{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some sort of PDF Project\n",
    "#### 2/27/2018 - 3/8/2018 | Victoria Larson | Sprint 7\n",
    "#### Description\n",
    "In this sprint I will be taking the hotel STR data (as i have in a previous sprint but this time i will combine multiple pdfs together to create one large table. This way I will be able to analyze the data over time and eventually use it to creat basic plots as well as a dashboard. \n",
    "\n",
    "## Skill Backlog User Story\n",
    "As a resource coordinator I need to construct data from **obscure places** so that I can create dashboards and basic plots of the resources I am coordinating. \n",
    "\n",
    "## Project Proposal\n",
    "The goal is to eventually become proficient enough in practice of pulling data from obscure places that I will be able to just upload the obscure data, run the code, and then be able to easily analyze it without hours of organization. \n",
    "\n",
    "## Key Questions\n",
    "- What are the best tools to use when pulling data from PDFs as well as when web scraping. \n",
    "- What questions to I ask so I can organize my data accordingly. \n",
    "\n",
    "\n",
    "## Key Findings\n",
    "- A running list of things that I'm learning and don't want to forget\n",
    "\n",
    "## Gameplan\n",
    "Here is my overall approach \n",
    "1. I will get all of the Hotel STR data into my folder 7.\n",
    "2. Start by analyzing the last project that I did when I used the STR data. \n",
    "3. Ask my questions so I know how I want to organize my data.\n",
    "4. Get all of the data into the same table (binding?)\n",
    "5. Organize the data! (This might happen in step 5)\n",
    "\n",
    "---\n",
    "\n",
    "## Day 1 Work\n",
    "\n",
    "Working on my project - pretty easy so far because I am just copying and pasting all of my work from sprint 4 but it looks like I will have to manually do all of the files so now I am kind of wanting to create a function to make it easier for me to throw the file into R and automatically get it out. \n",
    "\n",
    "## Day 2 Work\n",
    "\n",
    "I made the function! life is good! \n",
    "some problems that I had which I conquered were using some functions that turned the data set from a character to a list, I fixed this by using the unlist function but it was pretty frustrating.\n",
    "\n",
    "Next I will be figuring out how to get all of the tables together so I am able to analyze them all. It may have been a mistake to already add the names to all of the data but we will see! \n",
    "\n",
    "Okay so I decided I only want part of the data on page, I only want to analyze the data for the week and not the running 28 days. I will store the data with the entire page below just in case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in loadfile(pdf): argument \"pdf\" is missing, with no default\n",
     "output_type": "error",
     "traceback": [
      "Error in loadfile(pdf): argument \"pdf\" is missing, with no default\nTraceback:\n",
      "1. pdf_text()",
      "2. poppler_pdf_text(loadfile(pdf), opw, upw)",
      "3. loadfile(pdf)"
     ]
    }
   ],
   "source": [
    "#set working directory\n",
    "setwd(\"/Users/victorialarson/Desktop/Dev_League/Repos/Sprint7\")\n",
    "\n",
    "# Using Libray pdftools\n",
    "library(pdftools)\n",
    "library(stringr)\n",
    "\n",
    "# Assigning a variable\n",
    "jan1 <- pdf_text()\n",
    "\n",
    "\n",
    "# Going to create functions to make this easier. listed below are mmy 6 files I will use. \n",
    "# \"0107_0113.pdf\"\n",
    "# \"0114_0120.pdf\"\n",
    "# \"0121_0127.pdf\"\n",
    "# \"0128_0203.pdf\"\n",
    "# \"0204_0210.pdf\"\n",
    "# \"0211_0217.pdf\"\n",
    "\n",
    "\n",
    "#getting page 3 from the file \n",
    "get_pg3_from_file = function(filename) {\n",
    "  file_text = pdf_text(filename)\n",
    "  # Want to focus on page 3 of the vector in the list.\n",
    "  page3 = file_text[[3]]\n",
    "  #Using regexpr to find the location of RevPAR\\n\n",
    "  tindex = regexpr(\"RevPAR\\n\", page3)\n",
    "  #deleting \"RevPAR\\n\" and everything before it using substring\n",
    "  page3 = substring(page3,tindex+7)\n",
    "  # String split with \"\\n\" - creates new lines\n",
    "  newline = strsplit(page3, \"\\n\")\n",
    "  #using substring turned my page into a list, i need it to be a character\n",
    "  newchar = unlist(newline)\n",
    "  #taking out all of the rows I dont need.\n",
    "  newchar = newchar[-(2)]\n",
    "  newchar = newchar[-(9)]\n",
    "  newchar = newchar[-(15)]\n",
    "  newchar = newchar[-(21)]\n",
    "  newchar = newchar[-(46:48)]\n",
    "  # Extracted all of the floats from the vectors\n",
    "  extract = (str_extract_all(newchar,\"[+-]?([0-9]*[.])?[0-9]+\"))\n",
    "  # turning the list back into a character\n",
    "  un_list = unlist(extract)\n",
    "  # telling it there need to be 18 lines\n",
    "  rep_list = rep(1:18, times=length(un_list)/18)\n",
    "  # I dont know whats going on here\n",
    "  split_list = split(un_list, rep_list)\n",
    "  # making the columns\n",
    "  df = cbind.data.frame(split_list, stringsAsFactors=F)\n",
    "  #adding column names\n",
    "  names(df) = c(\"CurrentWeek_2017_Occ\", \"CurrentWeek_2016_Occ\", \"CurrentWeek_2017_ADR\", \"CurrentWeek_2016_ADR\", \n",
    "                \"CurrentWeek_2017_RevPar\",\"CurrentWeek_2016_RevPar\",\"CurrentWeek_PercentChange_Occ\",\"CurrentWeek_PercentChange_ADR\",\"CurrentWeek_PercentChange_Revpar\",\n",
    "                \"28days_2017_Occ\",\"28days_2016_Occ\",\"28days_2017_ADR\",\"28days_2016_ADR\",\"28days_2017_RevPar\",\"28days_2016_RevPar\",\n",
    "                \"28days_PercentChange_Occ\",\"28days_PercentChange_ADR\",\"28days_PercentChange_Revpar\")\n",
    "  # Creating row names\n",
    "  row.names(df) = hotelnames\n",
    "  return(df)\n",
    "}\n",
    "\n",
    "# Creating vector called \"hotelnames\"\n",
    "hotelnames = c(\"Total United States\",\"ChainScale_Luxury\",\"ChainScale_Upper Upscale\",\"ChainScale_Upscale\",\"ChainScale_Upper Midscale\",\n",
    "               \"ChainScale_Midscale\",\"ChainScale_Economy\",\"ChainScale_Independents\",\"Class_Luxury\",\"Class_Upper_Upscale\",\"Class_Upscale\",\"Class_Upper_Midscale\",\n",
    "               \"Class_Midscale\",\"Class_Economy\",\"Location_Urban\",\"Location_Suburban\",\"Location_Airport\",\"Location_Interstate\",\"Location_Resort\",\"Location_Small_Metro/Town\",\"Anaheim\",\n",
    "               \"Atlanta\",\"Boston\",\"Chicago\",\"Dallas\",\"Denver\",\"Detroit\",\"Houston\",\"Los Angeles\",\"Miami\",\"Minneapolis\",\n",
    "               \"Nashville\",\"New Orleans\",\"New York\",\"Norfolk\",\"Oahu\",\"Orlando\",\"Philadelphia\",\"Phoenix\",\"San Diego\",\n",
    "               \"San Francisco\",\"Seattle\",\"St Louis\",\"Tampa/St Petersburg\",\"Washington DC\")\n",
    "\n",
    "Jan7_13 = get_pg3_from_file(\"0107_0113.pdf\")\n",
    "Jan14_20 = get_pg3_from_file(\"0114_0120.pdf\")\n",
    "Jan21_27 = get_pg3_from_file(\"0121_0127.pdf\")\n",
    "Jan28_Feb3 = get_pg3_from_file(\"0128_0203.pdf\")\n",
    "Feb4_10 = get_pg3_from_file(\"0204_0210.pdf\")\n",
    "Feb11_17 = get_pg3_from_file(\"0211_0217.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after a little research it looks like maybe the 28days is something I will just filter out later on. But for now I will try to bind the files together. \n",
    "\n",
    "cbind\n",
    "transpose\n",
    "\n",
    ":)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Peer Feedback on Day 3\n",
    "\n",
    "After talking it over with a peer, I received the following feedback and decided to make these changes\n",
    "\n",
    "## Here are some overall notes on the skills I learned\n",
    "And perhaps some stream of consciousness notes about what I did, and other questions I might have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
