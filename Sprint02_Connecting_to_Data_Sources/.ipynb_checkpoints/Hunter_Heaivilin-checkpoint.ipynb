{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Collecting and Appending Data\n",
    "#### 11/28/2017 | Hunter Heaivilin | Sprint 2\n",
    "#### Description\n",
    "Exploring various tools to grab data (downloads, web scraping, APIs), clean it as needed, and scraped websites to add to the existing data.\n",
    "\n",
    "## Skill Backlog User Story\n",
    "As a researcher, I need to understand command line-based applications, basic scripting, databases, web resources, APIs, and data warehouses so that I can download data from websites, connect to and query databases, interface with APIs, and web scrape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Projects\n",
    "\n",
    "- Go to website ([AGRICULTURAL DEDICATIONS](https://www.realpropertyhonolulu.com/dedications/agricultural-dedications/)\n",
    "- Grab pdf ([2017 Dedicated Agricultural Parcels list](https://www.realpropertyhonolulu.com/media/1465/ag.pdf)) \n",
    "- Parse pdf for relevant data \n",
    "- Compile data into some new format (e.g., csv), \n",
    "- Add a bit of the data onto a url as custom suffix\n",
    "- Go to url with custom suffix (e.g, http://qpublic9.qpublic.net/hi_honolulu_display.php?county=hi_honolulu&KEY=290170150000)\n",
    "- - Scrape data from url pages for more data that I want\n",
    "- add new data from url to existing dataset from pdf\n",
    "- join data with spatial dataset\n",
    "\n",
    "\n",
    "- Pull data from API ([Organic Integrity Database API](https://organic.ams.usda.gov/integrity/Developer/APIHelp.aspx))\n",
    "- Geocode [2017 Dedicated Agricultural Parcels list](https://www.realpropertyhonolulu.com/media/1465/ag.pdf) from site address (or TMK if can find good data) to csv with lat long (via geocodio or similar) and map with Python using Shaply and Fiona.\n",
    "- Perform similar but using [Organic Integrity Database API](https://organic.ams.usda.gov/integrity/Developer/APIHelp.aspx) to map certified organic farms in the state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Proposal\n",
    "--\n",
    "This is what I propose to do in this project and why I think it will be useful to me and my overall objective\n",
    "\n",
    "\n",
    "Go to a website ([AGRICULTURAL DEDICATIONS](https://www.realpropertyhonolulu.com/dedications/agricultural-dedications/) and download a pdf with tables in it([2017 Dedicated Agricultural Parcels list](https://www.realpropertyhonolulu.com/media/1465/ag.pdf)). Parse the pdf for relevant data and compile the data into a more useful format (e.g., csv). \n",
    "- Add a bit of the data onto a url as custom suffix\n",
    "- Go to url with custom suffix (e.g, http://qpublic9.qpublic.net/hi_honolulu_display.php?county=hi_honolulu&KEY=290170150000)\n",
    "- Parse url page for more data that I want\n",
    "- add new data from url to existing dataset from pdf\n",
    "- join data with spatial dataset\n",
    "\n",
    "\n",
    "\n",
    "## Key Questions\n",
    "- What doth R?\n",
    "- Call data from an existing set and use it to create custom urls\n",
    "- Webscraping tools and basic operation\n",
    "\n",
    "## Key Findings\n",
    "- R is wonderful\n",
    "- CRAN is my bu\n",
    "\n",
    "## Gameplan\n",
    "Here is my overall approach:\n",
    "1. Use R to go to the City and County of Honolulu's Real Property Assessment Division [website](https://www.realpropertyhonolulu.com/) to grab data about [agricultural dedications](https://www.realpropertyhonolulu.com/dedications/agricultural-dedications/) in the county.\n",
    "2. Download a pdf with tables of the . \n",
    "3. Parse the pdf for relevant data and compile the data into a more useful format (e.g., csv). \n",
    "4. Clean, if needed, the resulting file output\n",
    "5. Find a way to add the Tax Map Key (TMK, e.g., 290170150000) from csv file onto a url as a suffix to create a custom urls (e.g, http://qpublic9.qpublic.net/hi_honolulu_display.php?county=hi_honolulu&KEY=290170150000)\n",
    "6. Find a way to do this over and over\n",
    "7. Go to url with custom suffix \n",
    "8. Screap url more data that I want\n",
    "9. Add new data from url to existing dataset from pdf/csv\n",
    "\n",
    "*Stretch Goals*\n",
    "10. Geocode address data from pdf/csv\n",
    "11. Join with spatial dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day 1 Work\n",
    "--\n",
    "#### Compiling Data on Multiple Excel Sheets\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/80/Seal_of_Honolulu%2C_Hawaii.svg/2000px-Seal_of_Honolulu%2C_Hawaii.svg.png\" alt=\"Drawing\" align=\"right\" style=\"width: 70px\" />\n",
    "\n",
    "\n",
    "-  Went to RPAD [agricultural dedications](https://www.realpropertyhonolulu.com/dedications/agricultural-dedications/) page via browers and manually downloaded the [2017 Dedicated Agricultural Parcels list](https://www.realpropertyhonolulu.com/media/1465/ag.pdf) pdf.\n",
    "- - - -\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://cdns.tblsft.com/sites/all/themes/tabwow/logo.png\" alt=\"Drawing\" align=\"right\" style=\"width: 100px\"/>\n",
    "\n",
    "-  Opened the pdf in [Tableau](https://www.tableau.com/) which has a built in [Data Interpreter](https://onlinehelp.tableau.com/current/pro/desktop/en-us/data_interpreter.html) designed to help clean data that converts and opens the pdf as an .xlsx file, but each page (of 33) was on a new sheet. I now needed a way to compile the data from the 34 sheets (minus the extra first sheet that has the Tableau interpreter key) into a single excel or csv sheet. \n",
    "\n",
    "----\n",
    "<img src=\"https://www.rstudio.com/wp-content/uploads/2017/05/readxl-259x300.png\" alt=\"Drawing\" align=\"right\" style=\"width: 70px;\" />\n",
    "\n",
    "- The [Readxl](http://readxl.tidyverse.org/index.html) R package is able to grab, fairly simply, from multiple sheets in either and .xsl or .xslx file.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download file from url \n",
    "download.file(\"https://www.realpropertyhonolulu.com/media/1465/ag.pdf\", \"/Users/hunterheaivilin/agdedis.pdf\")\n",
    "\n",
    "#Convert pdf into excel or csv\n",
    "\n",
    "\n",
    "# Install necessary packages\n",
    "install.packages(\"readxl\")\n",
    "install.packages(\"purrr\")\n",
    "\n",
    "#Call package libraries\n",
    "library(readxl)\n",
    "library(purrr)\n",
    "\n",
    "#Define file\n",
    "file <- 'path'\n",
    "\n",
    "sheets <- excel_sheets(file)\n",
    "\n",
    "df <- map_df(sheets, ~ read_excel(file, sheet = 2, range = \"A2:D45\"))\n",
    "\n",
    "write.csv(df, file = \"df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day 2 Work\n",
    "--\n",
    "#### Downloading a File at a URL\n",
    "Used [Download.file](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/download.file.html) to grab file from website.\n",
    "\n",
    "\n",
    "- - - -\n",
    "#### Extracting Data from Tables in a PDF\n",
    "\n",
    " - - - -\n",
    "<img src=\"http://blog.infographics.tw/wp-content/uploads/2015/06/cover4.jpg\" alt=\"Drawing\" align=\"right\" style=\"width: 200px;\"/>\n",
    "\n",
    "\n",
    "1. Tried to follow [Extracting Tables from PDFs in R using the Tabulizer Package](https://www.r-bloggers.com/extracting-tables-from-pdfs-in-r-using-the-tabulizer-package/), which shows how to use the [Tabulizer](https://github.com/ropensci/tabulizer) package for R ([tutorial](https://ropensci.org/tutorials/tabulizer_tutorial/)), but unfortunately \n",
    " \n",
    "> install.packages(\"tabulizer\")\n",
    "\n",
    "> Warning in install.packages :\n",
    "\n",
    "> package ‘tabulizer’ is not available (for R version 3.4.2)\n",
    "\n",
    "Apparently others have had [this issue](https://github.com/ropensci/tabulizer/issues/44).\n",
    "Fortunately there is an app version called [Tabula](http://tabula.technology/) that works quite well!\n",
    "\n",
    "** *Caveat:* ** The csv output retained the column headers from each page, meaning some further post processing is still needed.\n",
    "</br >\n",
    "- - - -\n",
    "<img src=\"https://pdftables.com/images/pdftables-logo.svg\" alt=\"Drawing\" align=\"right\" style=\"width: 200px;\"/>\n",
    "\n",
    "2. [PDFTables](https://pdftables.com/) also has an [R package](https://github.com/expersso/pdftables) with an API to the [web app](https://pdftables.com/), there is a sparse [CRAN documentation](https://cran.r-project.org/web/packages/pdftables/pdftables.pdf) and [tutorial](https://cran.r-project.org/web/packages/pdftables/vignettes/convert_pdf_tables.html)\n",
    "\n",
    "- - - - \n",
    "3. [pdftools](https://cran.r-project.org/web/packages/pdftools/pdftools.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Peer Feedback on Day 3\n",
    "\n",
    "After talking it over with a peer, I received the following feedback and decided to make these changes\n",
    "\n",
    "## Here are some overall notes on the skills I learned\n",
    "And perhaps some stream of consciousness notes about what I did, and other questions I might have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/extensions/rmagic.py:11: UserWarning: The rmagic extension in IPython has moved to `rpy2.ipython`, please see `rpy2` documentation.\n",
      "  warnings.warn(\"The rmagic extension in IPython has moved to \"\n"
     ]
    }
   ],
   "source": [
    "%load_ext rmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rmagic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ab89f9ae44f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrmagic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rmagic' is not defined"
     ]
    }
   ],
   "source": [
    "rmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Line magic function `%R` not found.\n"
     ]
    }
   ],
   "source": [
    "%R getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
