{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Project Name\n",
    "#### [Date] | [Author] | [Sprint]\n",
    "#### Description\n",
    "1 to 2 sentence description. The first 5 Sections are mandatory. Free form after that, but there are a couple of suggested categories you can use. But really document however you feel the most comfortable.\n",
    "\n",
    "## Skill Backlog User Story\n",
    "As a [TKTKTK] I need [TKTKTK] So that [TKTKTK]\n",
    "\n",
    "## Project Proposal\n",
    "This is what I propose to do in this project and why I think it will be useful to me and my overall objective\n",
    "\n",
    "## Key Questions\n",
    "- Things I want to find out\n",
    "- Definitions I want to establish and clarify\n",
    "\n",
    "## Key Findings\n",
    "- A running list of things that I'm learning and don't want to forget\n",
    "\n",
    "## Gameplan\n",
    "Here is my overall approach \n",
    "1. Step 1\n",
    "2. Step 2\n",
    "3. Step 3\n",
    "4. Step 4\n",
    "\n",
    "---\n",
    "\n",
    "## Day 1 Work\n",
    "\n",
    "- Went to url and downloaded pdf file\n",
    "- opened file in tableau, which kicked out an xlsx version\n",
    "- \n",
    "\n",
    "## Day 2 Work\n",
    "\n",
    "Used [Download.file](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/download.file.html) to grab file from website.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Peer Feedback on Day 3\n",
    "\n",
    "After talking it over with a peer, I received the following feedback and decided to make these changes\n",
    "\n",
    "## Here are some overall notes on the skills I learned\n",
    "And perhaps some stream of consciousness notes about what I did, and other questions I might have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day 1 Work\n",
    "--\n",
    "#### Compiling Data on Multiple Excel Sheets\n",
    "\n",
    "[Readxl](http://readxl.tidyverse.org/index.html) package is able to grab, fairly simply, from multiple sheets in either and .xsl or .xslx file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Day 2 Work\n",
    "--\n",
    "#### Downloading a File at a URL\n",
    "Used [Download.file](https://stat.ethz.ch/R-manual/R-devel/library/utils/html/download.file.html) to grab file from website.\n",
    "\n",
    "\n",
    "- - - -\n",
    "#### Extracting Data Tabled in a PDF\n",
    "\n",
    " - - - -\n",
    "<img src=\"http://blog.infographics.tw/wp-content/uploads/2015/06/cover4.jpg\" alt=\"Drawing\" align=\"right\" style=\"width: 200px;\"/>\n",
    "\n",
    "\n",
    "1. Tried to follow [Extracting Tables from PDFs in R using the Tabulizer Package](https://www.r-bloggers.com/extracting-tables-from-pdfs-in-r-using-the-tabulizer-package/), which shows how to use the [Tabulizer](https://github.com/ropensci/tabulizer) package for R ([tutorial](https://ropensci.org/tutorials/tabulizer_tutorial/)), but unfortunately \n",
    " \n",
    "> install.packages(\"tabulizer\")\n",
    "\n",
    "> Warning in install.packages :\n",
    "\n",
    "> package ‘tabulizer’ is not available (for R version 3.4.2)\n",
    "\n",
    "Apparently others have had [this issue](https://github.com/ropensci/tabulizer/issues/44).\n",
    "Fortunately there is an app version called [Tabula](http://tabula.technology/) that works quite well!\n",
    "\n",
    "** *Caveat:* ** The csv output retained the column headers from each page, meaning some further post processing is still needed.\n",
    "- - - -\n",
    "<img src=\"https://pdftables.com/images/pdftables-logo.svg\" alt=\"Drawing\" align=\"right\" style=\"width: 200px;\"/>\n",
    "\n",
    "2. [PDFTables](https://pdftables.com/) also has an [R package](https://github.com/expersso/pdftables) with an API to the [web app](https://pdftables.com/), there is a sparse [CRAN documentation](https://cran.r-project.org/web/packages/pdftables/pdftables.pdf) and [tutorial](https://cran.r-project.org/web/packages/pdftables/vignettes/convert_pdf_tables.html)\n",
    "\n",
    "- - - - \n",
    "3. [pdftools](https://cran.r-project.org/web/packages/pdftools/pdftools.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/IPython/extensions/rmagic.py:11: UserWarning: The rmagic extension in IPython has moved to `rpy2.ipython`, please see `rpy2` documentation.\n",
      "  warnings.warn(\"The rmagic extension in IPython has moved to \"\n"
     ]
    }
   ],
   "source": [
    "%load_ext rmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ideas for projects:\n",
    "- Go to website ([AGRICULTURAL DEDICATIONS](https://www.realpropertyhonolulu.com/dedications/agricultural-dedications/)\n",
    "- Grab pdf ([2017 Dedicated Agricultural Parcels list](https://www.realpropertyhonolulu.com/media/1465/ag.pdf)) \n",
    "- Parse pdf for relevant data \n",
    "- Compile data into some new format (e.g., csv), \n",
    "- Add a bit of the data onto a url as custom suffix\n",
    "- Go to url with custom suffix (e.g, http://qpublic9.qpublic.net/hi_honolulu_display.php?county=hi_honolulu&KEY=290170150000)\n",
    "- Parse url page for more data that I want\n",
    "- add new data from url to existing dataset from pdf\n",
    "- join data with spatial dataset\n",
    "- \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Pull data from API ([Organic Integrity Database API](https://organic.ams.usda.gov/integrity/Developer/APIHelp.aspx))\n",
    "\n",
    "- Scrape datafrom webpages \n",
    "\n",
    "1. Convert geospatial data to other formats [GIS with Python, Shapely, and Fiona](https://macwright.org/2012/10/31/gis-with-python-shapely-fiona.html) \n",
    "\n",
    "2. Look at the different ways to interact with geospatial files in a gui vs. r vs python.\n",
    "\n",
    "3. Run spatial analysis to cross-tabulate species suitability areas for multiple crops by island through different means (e.g., ArcGIS vs Python vs R); and create a streamlined process to do similar analysis in the future (e.g, ArcGIS ModelBuilder or script)\n",
    "\n",
    "4. Geocode [2017 Dedicated Agricultural Parcels list](https://www.realpropertyhonolulu.com/media/1465/ag.pdf) from site address (or TMK if can find good data) to csv with lat long (via geocodio or similar) and map with Python using Shaply and Fiona.\n",
    "\n",
    "5. Perform similar but using [Organic Integrity Database API](https://organic.ams.usda.gov/integrity/Developer/APIHelp.aspx) to map certified organic farms in the state.\n",
    "\n",
    "6. Convert some ~~shapefile~~ GIS file formats (potentially [local rainfall](http://rainfall.geography.hawaii.edu/downloads.html), which is in GRID format not a shapefile) into csv with lat long points using Python or R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rmagic' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ab89f9ae44f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrmagic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'rmagic' is not defined"
     ]
    }
   ],
   "source": [
    "rmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Line magic function `%R` not found.\n"
     ]
    }
   ],
   "source": [
    "%R getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download file from url \n",
    "download.file(\"https://www.realpropertyhonolulu.com/media/1465/ag.pdf\", \"/Users/hunterheaivilin/agdedis.pdf\")\n",
    "\n",
    "#Convert pdf into excel or csv\n",
    "\n",
    "\n",
    "# Install necessary packages\n",
    "install.packages(\"readxl\")\n",
    "install.packages(\"purrr\")\n",
    "\n",
    "#Call package libraries\n",
    "library(readxl)\n",
    "library(purrr)\n",
    "\n",
    "#Define file\n",
    "file <- 'path'\n",
    "\n",
    "sheets <- excel_sheets(file)\n",
    "\n",
    "df <- map_df(sheets, ~ read_excel(file, sheet = 2, range = \"A2:D45\"))\n",
    "\n",
    "write.csv(df, file = \"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
