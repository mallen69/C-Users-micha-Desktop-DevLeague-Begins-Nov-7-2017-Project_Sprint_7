{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Basic Data Manipulation Sprint Journal for Natalie Ramirez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## DAY 1: Tuesday (Week 1)\n",
    "### What I Expect to Learn\n",
    "* Replace with a summary of what you hope to accomplish with this project and how it fits into your overall roadmap. This includes key questions such as things you want to find out and definitions you want to establish and clarify.\n",
    "I expect to learn faster ways of cleansing data using tools and also determine different ways of updating databases using different libraries.\n",
    "\n",
    "### Project References\n",
    "- http://dataconomy.com/2015/03/14-best-python-pandas-features/\n",
    "- https://stackoverflow.com/questions/28699903/how-can-i-link-a-google-spreadsheet-to-postgresql\n",
    "- https://medium.com/ibotta-engine/scaling-from-manual-to-automated-reporting-using-pandas-google-scripts-and-google-sheets-a8a9c9b3ff94\n",
    "\n",
    "### Project Pitch\n",
    "- Connect an enrollment form created in google forms to postgresql database using google scripts and pandas in python used to update student data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposed Plan: Key Milestones by Day\n",
    "\n",
    "##### Day 2 (Wed Week 1):\n",
    "- Develop Project Milestones\n",
    "- Push Docs / Repo / Roadmap Update\n",
    "- Create google enrollment form\n",
    "\n",
    "##### Day 3 (Thu Week 1):\n",
    "- Create script to connect google sheet form to Postgres\n",
    "- Test to see if it works\n",
    "- Push docs / repo\n",
    "\n",
    "##### Day 4 (Tue Week 2):\n",
    "- Use pandas to explore data\n",
    "- Use pandas and matplotlib to cleanse and describe\n",
    "- Visualize data with matplotlib\n",
    "- Push docs / repo\n",
    "\n",
    "##### Day 5 (Wed Week 2):\n",
    "- Project highlights\n",
    "- Identify question or cohort knowledge gap for sprint review\n",
    "- Develop Topic Project + Presentation\n",
    "- Push Repo / docs / Presentation\n",
    "\n",
    "#### Project Definition and README.MD Discussion\n",
    "This is a discussion of how this project will fit into my overall roadmap. I will update my roadmap with the following project definition\n",
    "\n",
    "I will focus my project Repo's README.MD on the same topic, but with this additional detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## DAY 2: Wednesday (Week 1)\n",
    "### Pitch Feedback \n",
    "- Try using Orator ORM\n",
    "- Use time to complete Data Model for centralized data store\n",
    "\n",
    "### Prototype Notes\n",
    "- Connecting google sheets to postgres using python is not that hard.\n",
    "- Had to do some manipulation in google scripts.\n",
    "- Extracting the data is giving me bugs.\n",
    "- Getting the data in the correct format was giving me issues as well.\n",
    "- Still just working with flat data.\n",
    "\n",
    "### Pair Show & Tell Comments\n",
    "*Comments from prototype discussion*\n",
    "\n",
    "*These comments lead into plan development. Key considerations for me and my partner:  Do I have a plan? Is my plan feasible?*\n",
    "- May need more than one form.\n",
    "- This project may be a little simple and if there's time allowed, I should work on my data model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## DAY 3: Thursday (Week 1)\n",
    "\n",
    "#### Setup for Repo and Documentation Push\n",
    "*Setup and testing I did to make sure my repo and documentation were ready to push at the end of the day*\n",
    "\n",
    "#### Repo File Strategy Discussion\n",
    "*How I will present my repo files for clarity and demonstration*\n",
    "\n",
    "#### Work towards milestone 1\n",
    "- Script to connect to PostgreSql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas, pyscopg, gspread\n",
    "\n",
    "#input database credentials\n",
    "user = raw_input(“username:”)\n",
    "password = raw_input(“password:”)\n",
    "\n",
    "#connect to db\n",
    "try:\n",
    "con = psycopg2.connect(database=’hsbd’, user=nat, host=’localhost’)\n",
    "cur = con.cursor()\n",
    "\n",
    "#run query and read to dataframe\n",
    "query_results = pandas.read_sql_query(“””SELECT * FROM enrollment“””, con)\n",
    "\n",
    "#if there's an error, print out what the error is\n",
    "except psycopg2.DatabaseError, e:\n",
    "print ‘Error %s’ % e\n",
    "sys.exit(1)\n",
    "\n",
    "#close the database connection\n",
    "finally:\n",
    "if con:\n",
    "    con.close()\n",
    "\n",
    "#print out the first five rows of the query to verify that results match what’s expected\n",
    "print query_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work towards milestone 2\n",
    "- Script using gspread library \n",
    "- In order for me to use the gspread library, I had to publish my googlesheet publicly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initiate and execute gspread connection to connect to google sheets\n",
    "scope = [‘https://spreadsheets.google.com/enrollment_form']\n",
    "         \n",
    "#input correct name of json file - you will get this when you set up your gspread module\n",
    "credentials = ServiceAccountCredentials.from_json_keyfile_name(‘enrollmentjsonfile.json’, scope)\n",
    "         \n",
    "#authenticate the connection\n",
    "gc = gspread.authorize(credentials)\n",
    "         \n",
    "#open the google sheet \n",
    "wks = gc.open(“enrollment_form”).sheet1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work towards milestone 3\n",
    "- Script to write to googlesheet\n",
    "- This solution would be a great solution if I was working with public data unfortunately the data I would be working with contains personal information about applicants. \n",
    "- This solution will not work for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character in identifier (<ipython-input-1-4c57443b1bad>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4c57443b1bad>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    cell_list = wks.range(‘A1:F1’)\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"
     ]
    }
   ],
   "source": [
    "# columns names\n",
    "columns = query_results.columns.values.tolist()\n",
    "\n",
    "# selection of the range that will be updated\n",
    "cell_list = wks.range(‘A1:F1’)\n",
    "\n",
    "# modifying the values in the range\n",
    "for cell in cell_list:\n",
    "    val = columns[cell.col-1]\n",
    "if type(val) is str:\n",
    "    val = val.decode(‘utf-8’)\n",
    "    cell.value = val\n",
    "\n",
    "# update column headers in batch to google sheet\n",
    "wks.update_cells(cell_list)\n",
    "\n",
    "# number of lines and columns\n",
    "num_lines, num_columns = query_results.shape\n",
    "\n",
    "# Select a cell range for results\n",
    "cell_list = wks.range(‘A2:’+numberToLetters(num_columns)+str(num_lines+1))\n",
    "\n",
    "# Update values\n",
    "for cell in cell_list:\n",
    "    val = query_results.iloc[cell.row-2,cell.col-1]\n",
    "    \n",
    "if type(val) is str:\n",
    "    val = val.decode(‘utf-8’)\n",
    "elif isinstance(val, (int, long, float, complex)):\n",
    "    \n",
    "    # note that we round all numbers\n",
    "    val = int(round(val))\n",
    "    cell.value = val\n",
    "\n",
    "    # Send results to update sheet in batch mode\n",
    "    wks.update_cells(cell_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DAY 4: Tuesday (Week 2)\n",
    "\n",
    "#### Work in Progress Feedback \n",
    "- Didn't get much feedback from my WIP due to me having to pivot from my original idea. I will now just use mock data in a csv file and use pandas, numpy and matplotlib to perform some data manipulation.\n",
    "\n",
    "#### Work towards milestone\n",
    "- Script to read in csv file using pandas\n",
    "- Understanding the data:\n",
    "  - I started by using the pandas library to read in my csv file. By utilizing the .index() and .columns() I was able to see the number of rows and columns in my dataframe.\n",
    "\n",
    "  - I then used the .head() method which is a method on a dataframe object and passed in the number 10 so I can just see the first 10 rows of data.\n",
    "  \n",
    "  - After running this script I automatically knew there were 1000 rows were in the file, so this is the starting point to validate a few things against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Reading the dataset in a dataframe using Pandas\n",
    "df = pd.read_csv(\"./data/mock_app_data.csv\") \n",
    "\n",
    "#returns number of rows\n",
    "print(\"num of rows: \", len(df.index))\n",
    "\n",
    "#returns number of columns\n",
    "print(\"num of columns: \", len(df. columns))\n",
    "\n",
    "#returns first 10 rows with header\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "num of rows:  1000\n",
    "num of columns:  11\n",
    "\n",
    "Out[2]:\n",
    "id\tfirst_name\tlast_name\temail\tgender\tstreet_address\tcity\tstate\tdate_applied\tprogession\tincome\n",
    "0\t1000\tEwan\tMarkovich\temarkovich0@csmonitor.com\tMale\t6 Brickson Park Place\tColumbus\tOhio\t05/28/2016\tSenior Sales Associate\t44951.0\n",
    "1\t1001\tDarcee\tShardlow\tdshardlow1@live.com\tFemale\t40977 Hanover Parkway\tLancaster\tPennsylvania\t07/04/2016\tPhysical Therapy Assistant\t42699.0\n",
    "2\t1002\tMatt\tSwancott\tmswancott2@npr.org\tMale\t514 6th Junction\tOmaha\tNebraska\t12/15/2017\tMedia Manager I\t74225.0\n",
    "3\t1003\tMeade\tHillin\tmhillin3@nationalgeographic.com\tMale\t2639 Cardinal Street\tRiverside\tCalifornia\t09/27/2017\tResearch Assistant III\t53885.0\n",
    "4\t1004\tLeese\tGarahan\tlgarahan4@sphinn.com\tFemale\t66 Blue Bill Park Pass\tLas Vegas\tNevada\t01/20/2016\tSales Associate\t50149.0\n",
    "5\t1005\tGwendolen\tPalia\tgpalia5@patch.com\tFemale\t507 Anzinger Place\tChicago\tIllinois\t04/28/2016\tVP Quality Control\t71921.0\n",
    "6\t1006\tHorten\tHickford\thhickford6@discuz.net\tMale\t42586 Rockefeller Alley\tFort Smith\tArkansas\t12/10/2017\tSoftware Test Engineer III\t72968.0\n",
    "7\t1007\tTheodor\tMacCallum\ttmaccallum7@shutterfly.com\tMale\t064 Cottonwood Place\tSaint Louis\tMissouri\t06/10/2017\tSafety Technician I\t40023.0\n",
    "8\t1008\tHedda\tFinkle\thfinkle8@cbc.ca\tFemale\t7 Bowman Lane\tHouston\tTexas\t06/04/2016\tBudget/Accounting Analyst I\t69307.0\n",
    "9\t1009\tHuntlee\tPoles\thpoles9@geocities.com\tMale\t174 Ramsey Pass\tAtlanta\tGeorgia\t02/15/2017\tAccount Representative III\t60884.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work towards milestone 2\n",
    "- Data Exploration\n",
    "\n",
    "  - Using the ```.describe()``` function I was able to see the count, mean, standard deviation (std), min, quartiles and max in its output. We will ignore the id column since it's just an application id and we don't need to do any analysis on it. \n",
    "\n",
    "  - We can see from the output that there are rows in the income column is missing 55 values since the file has 1000 rows and count returned 945.\n",
    "\n",
    "  - Using ```df['female'].value_counts()``` function we can determine how many applicants were male and how many were female. From this I can determine that there are 44 missing records from gender by adding both counts together and subtracting from the total row count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "id\tincome\n",
    "count\t1000.000000\t945.000000\n",
    "mean\t1499.500000\t54601.469841\n",
    "std\t288.819436\t11397.859584\n",
    "min\t1000.000000\t35040.000000\n",
    "25%\t1249.750000\t44827.000000\n",
    "50%\t1499.500000\t54309.000000\n",
    "75%\t1749.250000\t64599.000000\n",
    "max\t1999.000000\t74953.000000\n",
    "In [11]:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work towards milestone 3\n",
    "- See Project Repo for Data Visualization\n",
    "    - [Data Manipulation](https://github.com/nat-nat33/data-manipulation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## DAY 5: Wednesday (Week 2)\n",
    "\n",
    "### Project Highlights: The things I am most excited about in my project\n",
    "Me\n",
    "- Pandas is pretty amazing and really easy to use not only for data manipulation but for data cleansing. \n",
    "- Previously sitting there for hours looking at excel and doing this process manually was very time consuming. Pandas does everything and more in seconds.\n",
    "- I like that data can be visualized very quickly without having to use a framework within an application.\n",
    "\n",
    "Peer Identified\n",
    "\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "### Peer Repo Feedback \n",
    "\n",
    "*Here are the changes I am making to my repo structure for additional clarity* \n",
    "- \n",
    "- \n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 6: Thursday (Week 2)\n",
    "--- \n",
    "\n",
    "#### Things I didn't get to\n",
    "*Here are some ideas that I didn't get to implement, but wanted to. I will be adding these to my roadmap table entry for this sprint as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
