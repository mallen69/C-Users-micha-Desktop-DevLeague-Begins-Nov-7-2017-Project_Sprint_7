{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Manipulation Libraries and Tools\n",
    "*Module: Basic Data Manipulation (Sprint 2 of 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint Module Review and Data Stories\n",
    "\n",
    "#### Basic Data Manipulation\n",
    "*Before you engage in structured analysis, you often just want to see the data. This can mean pre-viewing a subset of it, summarize the columns/attributes/features, sorting or reorganizing it and otherwise finding ways to immerse yourself in your data. Different technologies tools have something different to offer, and our objective is to develop a good sense of the utilities available to you*\n",
    "\n",
    "|Data Journalist| Data Engineer | Statistical Modeler| Business Analyst |\n",
    "|----|----------------|------------------|----|\n",
    "|… I need to be able to **convert published research and analysis from Excel / R / Python** into a different tool so I can verify and audit the analysis|… I need to understand the **basic data structures in Python** so that I can diagnose and troubleshoot performance issues|…I need to understand the **NumPy arrays and Pandas / R dataframes** so I can supply data to algorithms, fit models, etc|… I need to understand how to export my **advanced excel skills to R / Python** so that I can build more powerful analyses on top of what I already know|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Process Big Picture\n",
    "![Curriculum Summary](../curriculum_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Tools Capstone\n",
    "What you have so far:\n",
    "- A map/taxonomy of technologies: Programming languages, editors, command line environments, source control, publishing, cloud computing\n",
    "- awareness of several \"languages\": SQL, R, Python\n",
    "- a basic idea of the components of programming\n",
    "- vocabulary of data and computing concepts\n",
    "- some experience assembling some of these pieces into projects, and using these tools\n",
    "\n",
    "### Tools development never stops\n",
    "You will not master these tools today. You won't master them this year. You won't master them in 10 years. You **will** develop a clearer and clearer picture of what you need to do and the most efficient ways to do it with increased **practice** and **experience**\n",
    "\n",
    "This sprint is about building a map of the available tools so you can access them when ready, and drafting a process that you can use to learn them on a continuing basis\n",
    "\n",
    "### Where do data manipulation tasks fit into the big picture above?\n",
    "- Exploratory Data Analysis:\n",
    "        - Creating\n",
    "        - Combining\n",
    "        - Converting\n",
    "        - Cleaning\n",
    "- Descriptive Statistics: Formatting / Summarizing\n",
    "- Basic Data Visualization: Formatting Data / Visualizing\n",
    "- Inferential Statistics: Sampling\n",
    "- Modeling: Preparing Data for input into\n",
    "- Data Governance: Anonymizing and Sanitizing\n",
    "        - Removing\n",
    "        - encrypting\n",
    "- Production Development: Everything\n",
    "- Data Products\n",
    "        - Creating APIs\n",
    "        - exporting data\n",
    "        - connecting data to clients\n",
    "        - formatting it\n",
    "\n",
    "### What do the Libraries do?\n",
    "- https://www.quora.com/What-are-the-Python-libraries-that-are-used-by-data-scientists/answer/Jared-Stufft-1\n",
    "\n",
    "### EVERYTHING. So why do we need to do anything? \n",
    "- Swiss Army knife: Clever, but takes some practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Key Concepts and Definitions\n",
    "- library\n",
    "- package\n",
    "- function\n",
    "- function call\n",
    "- ecosystem\n",
    "- Pandas\n",
    "- Numpy\n",
    "- Tidyverse\n",
    "\n",
    "## Key Questions\n",
    "- What is a library?\n",
    "- What is a package?\n",
    "- How do I get them?\n",
    "- How are they created?\n",
    "- What libraries / packages are available to me?\n",
    "- What do each of them do?\n",
    "- How do I learn about them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Ecosystem\n",
    "\n",
    "![Python Ecosystem](00_images/python.jpeg)\n",
    "https://www.quora.com/What-is-the-relationship-among-NumPy-SciPy-Pandas-and-Scikit-learn-and-when-should-I-use-each-one-of-them/answer/Jeremy-Langley\n",
    "\n",
    "These are all tools in the field of data science. The lower level you get the faster speeds you can achieve. The higher level you go the more interesting problems you might be able to solve. You can see which sits on top of another thanks to Jake Vanderplas\n",
    "\n",
    "\"Numpy is the lowest level sitting on Python. It reads in fixed datatypes. It's data layout is more concerned with efficiency of memory. If you are dealing with strings they are fixed length strings. (fit the data size for each element to the longest string length) but it shines when you are dealing with number calculations. The more you can think in vectors the faster your code runs. (learn how to get rid of the for statements for speed reasons by using Numpy broadcasting)\n",
    "\n",
    "Pandas is spreadsheets for Python (something like R). It's able to describe the data for you. It can do grouping and pivot tables on larger data than most spreadsheet programs out there. The only limit (currently) is how much RAM you have on the machine same as Numpy. However there is a project Blaze which is helping to overcome this limit.\"\n",
    "\n",
    "## R Ecosystem - Tidyverse\n",
    "![Tidyverse](00_images/hex-tibble.png)\n",
    "![Tidyverse](00_images/hex-dplyr.png)\n",
    "![Tidyverse](00_images/hex-ggplot2.png)\n",
    "![Tidyverse](00_images/hex-purrr.png)\n",
    "![Tidyverse](00_images/hex-readr.png)\n",
    "![Tidyverse](00_images/hex-tidyr.png)\n",
    "\n",
    "- https://www.tidyverse.org/\n",
    "- http://fg2re.sellorm.com/\n",
    "- https://hawaiimachinelearning.github.io/event/2017/12/18/exploratory-data-analysis-tidyverse/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Ideas\n",
    "\n",
    "- Using a dataset that you care about, use each function in a library to see what it does and how it works\n",
    "- Create a collection of examples of projects on github that use each of the functions you're interested in. \n",
    "- Try to implement functions from the libraries manually and compare the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sheuli', 'hunter', 'michael', 'runjini', 'nat', 'olina', 'tori', 'jon']\n",
      "Day 1/2/3:\n",
      "['sheuli', 'hunter', 'michael', 'runjini', 'nat', 'olina', 'tori', 'jon']\n",
      "Day 4/5/6:\n"
     ]
    }
   ],
   "source": [
    "#Randomizer\n",
    "import random\n",
    "import numpy\n",
    "cohort = [\"hunter\",\"jon\",\"michael\",\"olina\", \"nat\", \"runjini\", \"sheuli\",\"tori\"]\n",
    "random.shuffle(cohort)\n",
    "\n",
    "print(\"Day 1/2/3:\")\n",
    "print(cohort)\n",
    "numpy.roll(cohort,1)\n",
    "print(cohort)\n",
    "print(\"Day 4/5/6:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
