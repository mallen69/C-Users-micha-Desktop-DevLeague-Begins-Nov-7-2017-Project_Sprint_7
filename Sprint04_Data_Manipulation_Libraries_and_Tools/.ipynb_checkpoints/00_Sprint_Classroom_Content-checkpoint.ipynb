{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Manipulation Libraries and Tools\n",
    "*Module: Basic Data Manipulation (Sprint 2 of 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sprint Module Review and Data Stories\n",
    "\n",
    "#### Basic Data Manipulation\n",
    "*Before you engage in structured analysis, you often just want to see the data. This can mean pre-viewing a subset of it, summarize the columns/attributes/features, sorting or reorganizing it and otherwise finding ways to immerse yourself in your data. Different technologies tools have something different to offer, and our objective is to develop a good sense of the utilities available to you*\n",
    "\n",
    "|Data Journalist| Data Engineer | Statistical Modeler| Business Analyst |\n",
    "|----|----------------|------------------|----|\n",
    "|… I need to be able to **convert published research and analysis from Excel / R / Python** into a different tool so I can verify and audit the analysis|… I need to understand the **basic data structures in Python** so that I can diagnose and troubleshoot performance issues|…I need to understand the **NumPy arrays and Pandas / R dataframes** so I can supply data to algorithms, fit models, etc|… I need to understand how to export my **advanced excel skills to R / Python** so that I can build more powerful analyses on top of what I already know|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytical Process Big Picture\n",
    "![Curriculum Summary](../curriculum_summary.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Tools Capstone\n",
    "What you have so far:\n",
    "- A map/taxonomy of technologies: Programming languages, editors, command line environments, source control, publishing, cloud computing\n",
    "- awareness of several \"languages\": SQL, R, Python\n",
    "- a basic idea of the components of programming\n",
    "- vocabulary of data and computing concepts\n",
    "- some experience assembling some of these pieces into projects, and using these tools\n",
    "\n",
    "### Tools development never stops\n",
    "You will not master these tools today. You won't master them this year. You won't master them in 10 years. You **will** develop a clearer and clearer picture of what you need to do and the most efficient ways to do it with increased **practice** and **experience**\n",
    "\n",
    "This sprint is about building a map of the available tools so you can access them when ready, and drafting a process that you can use to learn them on a continuing basis\n",
    "\n",
    "### Where do data manipulation tasks fit into the big picture above?\n",
    "- Exploratory Data Analysis:\n",
    "        - Creating\n",
    "        - Combining\n",
    "        - Converting\n",
    "        - Cleaning\n",
    "- Descriptive Statistics: Formatting / Summarizing\n",
    "- Basic Data Visualization: Formatting Data / Visualizing\n",
    "- Inferential Statistics: Sampling\n",
    "- Modeling: Preparing Data for input into\n",
    "- Data Governance: Anonymizing and Sanitizing\n",
    "        - Removing\n",
    "        - encrypting\n",
    "- Production Development: Everything\n",
    "- Data Products\n",
    "        - Creating APIs\n",
    "        - exporting data\n",
    "        - connecting data to clients\n",
    "        - formatting it\n",
    "\n",
    "### What do the Libraries do?\n",
    "https://www.quora.com/What-are-the-Python-libraries-that-are-used-by-data-scientists/answer/Jared-Stufft-1\n",
    "all of it. So why do we need to do anything? \n",
    "Sorcerers Apprentice\n",
    "something hard to control... analogy. Boat? firehose?\n",
    "\n",
    "Python\n",
    "https://www.quora.com/What-is-the-relationship-among-NumPy-SciPy-Pandas-and-Scikit-learn-and-when-should-I-use-each-one-of-them/answer/Jeremy-Langley\n",
    "\n",
    "These are all tools in the field of data science. The lower level you get the faster speeds you can achieve. The higher level you go the more interesting problems you might be able to solve. You can see which sits on top of another thanks to Jake Vanderplas\n",
    "\n",
    "\"Numpy is the lowest level sitting on Python. It reads in fixed datatypes. It's data layout is more concerned with efficiency of memory. If you are dealing with strings they are fixed length strings. (fit the data size for each element to the longest string length) but it shines when you are dealing with number calculations. The more you can think in vectors the faster your code runs. (learn how to get rid of the for statements for speed reasons by using Numpy broadcasting)\n",
    "\n",
    "Pandas is spreadsheets for Python (something like R). It's able to describe the data for you. It can do grouping and pivot tables on larger data than most spreadsheet programs out there. The only limit (currently) is how much RAM you have on the machine same as Numpy. However there is a project Blaze which is helping to overcome this limit.\"\n",
    "\n",
    "R - Tidyverse\n",
    "https://www.tidyverse.org/\n",
    "https://hawaiimachinelearning.github.io/event/2017/12/18/exploratory-data-analysis-tidyverse/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Key Concepts and Definitions\n",
    "\n",
    "## Key Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Ideas\n",
    "\n",
    "From Justin for Both Sprints on Basic Data Operations\n",
    "- Inspect the contents of the files programmatically with a for loop!!!!\n",
    "- Count the lines in the file, Count the entries. Is there any metadata? What is it?\n",
    "- Clean the data with pandas or (r-based dataframe library)\n",
    "- Save the new data file to disk (Or push it to s3!!!)\n",
    "- Tools: Open the data with python libraries, csv, pandas, xarray, or pure python\n",
    "- apply each function in R / SQL / Python to your dataset\n",
    "- compare functionality between the 3 languages. Do a read in each language, a \"select\" query in each language, a join in each language\n",
    "- research the usefulness of each function for your dataset\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
