{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data Manipulation Libraries & Tools\n",
    "# Sprint Journal for Jon Honda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "## DAY 1: Tuesday (Week 1)\n",
    "### What I Expect to Learn\n",
    "* Identify libaries that may help me refactor my special project coding.\n",
    "* How to more efficiently research and evaluate applicability, effectiveness, quality of libraries to use in projects.\n",
    "* How does one come to a decision between code refactoring to implement library, versus using existing code as is, versus looking for a better solution using \"native\"/non-library code?\n",
    "\n",
    "### Project References\n",
    "- *https://orator-orm.com/* an \"object oriented\" approach to SQL coding.\n",
    "    https://github.com/sdispater/orator\n",
    "    https://www.fullstackpython.com/object-relational-mappers-orms.html\n",
    "    https://codedump.io/share/40C5X02B8ie1/1/using-sqlalchemy-to-load-csv-file-into-a-database\n",
    "- *replace with Link to project and description of why it's of interest to you*\n",
    "- *https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.basinhopping.html* a simulated annealing like solution\n",
    "   https://www.hindawi.com/journals/aai/2012/674832/ is a paper describing the algorithm\n",
    "\n",
    "### Project Pitch\n",
    "- *Identifiy libraries to assist in refactoring special project coding*\n",
    "- *This project relates to data manipulation libraries as because of specic refactoring i envision will need to be done:*\n",
    "  - Working with SQL w/in your solution is tedious, prone to errors, makes for difficult to read code.  Is there a more elegant solution?\n",
    "  - Working with operations on tables, matrix-like operations. Are there libraries to assist?\n",
    "  - Finding minimual solution front will require a simulated annealing like solution. Are there libraries to assist, so I don't need to write the algorithm myself? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## DAY 2: Wednesday (Week 1)\n",
    "### Pitch Feedback \n",
    "*After hearing my pitch, Ben suggested I look at ORM solutions to help me reduce complexity surrounding SQL-handling code*\n",
    "*After hearing my pitch, Justin suggested I look into Basin Hopping algorithm, which is implimented as a SciPy libary.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype Notes\n",
    "*Results from prototype experiments, snippets of code, things I tried * \n",
    "Researching ORMs - i've discovered there's a lot of them out there. Orator-ORM is just one of them. It seems that for Python, a lot of folks like SQLAlchemy. There is a lot more documentation and information available for SQLAlchemy. SQLAlchemy's page says its used by lots of companies:\n",
    "http://www.sqlalchemy.org/organizations.html\n",
    "- hulu\n",
    "- cars.com\n",
    "- yelp\n",
    "\n",
    "\n",
    "\n",
    "Maybe I should switch to it.\n",
    "- *http://www.sqlalchemy.org/*\n",
    "- *http://www.rmunn.com/sqlalchemy-tutorial/tutorial.html*\n",
    "- *https://www.pythoncentral.io/overview-sqlalchemys-expression-language-orm-queries/*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair Show & Tell Comments\n",
    "*Comments from prototype discussion*\n",
    "\n",
    "*These comments lead into plan development. Key considerations for me and my partner:  Do I have a plan? Is my plan feasible?*\n",
    "\n",
    "### Proposed Plan: Key Milestones by Day\n",
    "\n",
    "##### Day 2 (Wed Week 1):\n",
    "- Develop Project Proposal\n",
    "- Push Docs / Repo / Roadmap Update\n",
    "\n",
    "##### Day 3 (Thu Week 1):\n",
    "- *milestone 1*\n",
    "- *milestone 2*\n",
    "- *milestone X...*\n",
    "- Push docs / repo\n",
    "\n",
    "##### Day 4 (Tue Week 2): \n",
    "- *milestone X+1*\n",
    "- *milestone X+2*\n",
    "- *milestone X+3*\n",
    "- Push docs / repo\n",
    "\n",
    "##### Day 5 (Wed Week 2):\n",
    "- Project highlights\n",
    "- Identify question or cohort knowledge gap for sprint review\n",
    "- Develop Topic Project + Presentation\n",
    "- Push Repo / docs / Presentation\n",
    "\n",
    "### Project Definition and README.MD Discussion \n",
    "*This is a discussion of how this project will fit into my overall roadmap. I will update my roadmap with the following project definition*\n",
    "\n",
    "*I will focus my project Repo's README.MD on the same topic, but with this additional detail.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## DAY 3: Thursday (Week 1)\n",
    "\n",
    "#### Setup for Repo and Documentation Push\n",
    "*Setup and testing I did to make sure my repo and documentation were ready to push at the end of the day*\n",
    "\n",
    "#### Repo File Strategy Discussion\n",
    "*How I will present my repo files for clarity and demonstration*\n",
    "\n",
    "#### Work towards milestone 1\n",
    "*Work I did towards Milestone *\n",
    "\n",
    "#### Work towards milestone 2\n",
    "*Work I did towards Milestone *\n",
    "\n",
    "#### Work towards milestone 3\n",
    "*Work I did towards Milestone *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## DAY 4: Tuesday (Week 2)\n",
    "\n",
    "#### Work in Progress Feedback \n",
    "*Feedback and ideas from my work in progress presentation *\n",
    "\n",
    "#### Work towards milestone 1\n",
    "*Work I did towards Milestone *\n",
    "\n",
    "#### Work towards milestone 2\n",
    "*Work I did towards Milestone *\n",
    "\n",
    "#### Work towards milestone 3\n",
    "*Work I did towards Milestone *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## DAY 5: Wednesday (Week 2)\n",
    "\n",
    "### Project Highlights: The things I am most excited about in my project\n",
    "Me\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "Peer Identified\n",
    "\n",
    "- \n",
    "- \n",
    "- \n",
    "\n",
    "### Peer Repo Feedback \n",
    "\n",
    "*Here are the changes I am making to my repo structure for additional clarity* \n",
    "- \n",
    "- \n",
    "- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day 6: Thursday (Week 2)\n",
    "--- \n",
    "\n",
    "#### Things I didn't get to\n",
    "*Here are some ideas that I didn't get to implement, but wanted to. I will be adding these to my roadmap table entry for this sprint as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#DEMONSTRATE A 1 TO MANY RELATIONSHIP W/O CORRESPONDING MANY TO 1 RELATIONSHIP\n",
    "    #THIS IS CRUCIAL WHEN WE HAVE SITUATIONS WHERE THE MANY SIDE TABLE OF A 1:MANY RELATIONSHIP \n",
    "    #DOES NOT NECESSARILY HAVE A CORRESPONDING RECORED ON THE 1 TABLE SIDE.\n",
    "    \n",
    "    \n",
    "#connect to SQLite DB w/ SQLAlchemy ORM:\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///:memory:', echo = False)\n",
    "\n",
    "\n",
    "#NOW DEFINE DB SCHEMA (THIS DOESN'T WRITE SCHEMA TO DB, JUST TO SQLALCHEMY CLASSES AND OBJECTS)\n",
    "#define an SQLAlchemy base class to maintain catalog of classes and tables relative to this base\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "Base = declarative_base()\n",
    "\n",
    "#use the base class to define mapped classes in terms of it:\n",
    "#as an initial example, define a table called 'users' by defining a class called 'User'\n",
    "from sqlalchemy import Column, Integer, String\n",
    "# from sqlalchemy import Sequence\n",
    "from sqlalchemy import ForeignKey\n",
    "from sqlalchemy.orm import relationship #http://docs.sqlalchemy.org/en/latest/orm/basic_relationships.html#relationship-patterns    \n",
    "\n",
    "# Column(Integer, Sequence('user_id_seq'), primary_key=True)\n",
    "\n",
    "\n",
    "class User(Base):\n",
    "    __tablename__ = 'users'\n",
    "    id = Column(Integer,  primary_key=True)\n",
    "    name = Column(String(50))\n",
    "    fullname = Column(String(50))\n",
    "    password = Column(String(12))\n",
    "    #sets up 1 to many relationship between 1 user and many addresses\n",
    "    #define relationship in both tables so that elements added in one direction automatically become visible in the other direction. This behavior occurs based on attribute on-change events and is evaluated in Python, without using any SQL:\n",
    "    addresses = relationship(\"Address\") # setup 1 to many relation. addresses is a collection that holds related Address class objects\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"<User(name='%s', fullname='%s', password='%s')>\" % (\n",
    "                                self.name, self.fullname, self.password)\n",
    "    \n",
    "class Address(Base):\n",
    "    __tablename__ = 'addresses'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    email_address = Column(String, nullable=False)\n",
    "    user_id = Column(Integer, ForeignKey('users.id'))\n",
    "    #sets up many to 1 relationship between 1 user and many addresses\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"<Address(email_address='%s')>\" % self.email_address\n",
    "    \n",
    "    \n",
    "#NOW WRITE SCHEMA TO DB (THIS WRITES TO SQLITE DB):\n",
    "Base.metadata.create_all(engine) #build DB schema from Base objects\n",
    "\n",
    "# for t in Base.metadata.sorted_tables:\n",
    "#     print (t)\n",
    "# for fkey in employees.foreign_keys:\n",
    "#     print(fkey)\n",
    "    \n",
    "#NOW WRITE DATA TO DB. YOU NEED A SESSION OBJECT TO DO SO:\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "Session = sessionmaker(bind=engine) #define Session class, which is a factory for making session objects (poor naming choice, in my opinion - why the do it this way??!)\n",
    "session = Session() #make a session\n",
    "ed_user = User(name='ed', fullname='Ed Jones', password='edspassword') #make a record\n",
    "session.add(ed_user) # add  record held in object to the DB - but only as a temp. item (it's not yet comitted)\n",
    "session.add_all([\n",
    "    User(name='wendy', fullname='Wendy Williams', password='foobar'),\n",
    "    User(name='mary', fullname='Mary Contrary', password='xxg527'),\n",
    "    User(name='fred', fullname='Fred Thompson', password='blah')])\n",
    "\n",
    "mydict = {'name':'jake', 'fullname':'jake tonda', 'password': 'jagd'}\n",
    "session.add(User(**mydict))\n",
    "\n",
    "mydict = {'name':'ian', 'fullname':'ian miller', 'password': 'tulla'}\n",
    "myTable = Table('users', Base.metadata, autoload=True, autoload_with=engine)\n",
    "#                 print (type(myTable))\n",
    "#                 print (type(People))\n",
    "# myTable = Base.metadata.tables['users']\n",
    "# myInstance = myTable(name='fssred', fullname='Fred Thompson', password='blah')\n",
    "# session.add(myTable(**mydict))\n",
    "\n",
    "\n",
    "session.commit() #commit all pending transactions to DB\n",
    "\n",
    "#PLAYING W/ RELATIONSHIPS:\n",
    "jack = User(name='jack', fullname='Jack Bean', password='gjffdd')\n",
    "jack.addresses #no associated addresses yet. so addresses relationship collection returnes empty\n",
    "\n",
    "jack.addresses = [#insert some addresses\n",
    "    Address(email_address='jack@google.com'),\n",
    "    Address(email_address='j25@yahoo.com')]\n",
    "#write jack to DB:\n",
    "session.add(jack)\n",
    "session.commit()\n",
    "\n",
    "#now add an email into addresses that's not associated w/ any names\n",
    "myeml = Address(email_address='otters@mink.net')\n",
    "session.add(myeml)\n",
    "session.commit()\n",
    "\n",
    "#get all users:\n",
    "for rec in session.query(User):\n",
    "    print (rec)\n",
    "    \n",
    "#do a join type query:\n",
    "for rec in session.query(User.id, User.fullname, Address.email_address).filter(User.name == 'jack'):\n",
    "    print (rec)\n",
    "    \n",
    "#get all addresses:\n",
    "for rec in session.query(Address.email_address):\n",
    "    print (rec)\n",
    "\n",
    "myTable = Base.metadata.tables['users']\n",
    "myCol =  myTable.c['id']\n",
    "u=update(myTable)\n",
    "u=u.values({'fullname': 'Wendy Almon'})\n",
    "u.where(myCol.name == 2)\n",
    "session.execute(u)\n",
    "session.commit()\n",
    "for rec in session.query(myTable).filter(User.name == 'wendy'):\n",
    "    print (rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #it may be useful to iterate through the table and column objects:\n",
    "# from sqlalchemy import Table\n",
    "# #get table names:\n",
    "# myTables = Base.metadata.tables.keys()\n",
    "# for myTable in myTables:\n",
    "#     print (myTable)\n",
    "#     print (type(myTable))\n",
    "\n",
    "# #get tables:\n",
    "# print (Base.metadata.tables['users']) #access table by table name\n",
    "\n",
    "# #iterate through tables:\n",
    "# for t in Base.metadata.sorted_tables:\n",
    "#     print (t.name) #print name of each table object\n",
    "#     print (type(t))\n",
    "#     for acol in t.c: #access table's column collection\n",
    "#         print (acol)\n",
    "#         print (type(acol))\n",
    "\n",
    "# #access column w/ column name\n",
    "# myTable = Base.metadata.tables['users']\n",
    "# myCol = myTable.c['name']\n",
    "# print (myCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #import 1 table csv to database\n",
    "# #build SQLAlchemy objects, build DB:\n",
    "# #connect to SQLite DB w/ SQLAlchemy ORM:\n",
    "   \n",
    "# #connect to SQLite DB w/ SQLAlchemy ORM:\n",
    "# from sqlalchemy import create_engine\n",
    "# engine = create_engine('sqlite:///:memory:', echo = False)\n",
    "\n",
    "\n",
    "\n",
    "# #NOW DEFINE DB SCHEMA (THIS DOESN'T WRITE SCHEMA TO DB, JUST TO SQLALCHEMY CLASSES AND OBJECTS)\n",
    "# #define an SQLAlchemy base class to maintain catalog of classes and tables relative to this base\n",
    "# from sqlalchemy.ext.declarative import declarative_base\n",
    "# Base = declarative_base()\n",
    "\n",
    "# #use the base class to define mapped classes in terms of it:\n",
    "# #as an initial example, define a table called 'users' by defining a class called 'User'\n",
    "# from sqlalchemy import Column, Integer, String\n",
    "# # from sqlalchemy import Sequence\n",
    "# from sqlalchemy import ForeignKey\n",
    "# from sqlalchemy.orm import relationship #http://docs.sqlalchemy.org/en/latest/orm/basic_relationships.html#relationship-patterns    \n",
    "\n",
    "# from sqlalchemy import update\n",
    "\n",
    "# class People(Base):\n",
    "#     __tablename__ = 'people'\n",
    "#     id = Column(Integer,  primary_key=True)\n",
    "#     name = Column(String(50))\n",
    "#     ssn = Column(String(50))\n",
    "#     age = Column(Integer)\n",
    "    \n",
    "#     def __repr__(self):\n",
    "#         return \"<People(name='%s', ssn='%s', age='%s')>\" % (\n",
    "#                                 self.name, self.ssn, self.age)\n",
    "# # class People(Base):\n",
    "# #     __tablename__ = 'people'\n",
    "# #     id = Column(Integer,  primary_key=True)\n",
    "# #     name = Column(String(50))\n",
    "# #     ssn = Column(String(12))\n",
    "# #     age = Column(Integer)\n",
    "    \n",
    "# #     def __repr__(self):\n",
    "# #         return \"<People(name='%s', ssn='%s', age='%s')>\" % (\n",
    "# #                                 self.name, self.ssn, self.age)\n",
    "\n",
    "# #NOW WRITE SCHEMA TO DB (THIS WRITES TO SQLITE DB):\n",
    "# Base.metadata.create_all(engine) #build DB schema from Base objects\n",
    "   \n",
    "# #NOW WRITE DATA TO DB. YOU NEED A SESSION OBJECT TO DO SO:\n",
    "# from sqlalchemy.orm import sessionmaker\n",
    "# Session = sessionmaker(bind=engine) #define Session class, which is a factory for making session objects (poor naming choice, in my opinion - why the do it this way??!)\n",
    "# session = Session() #make a session\n",
    "\n",
    "# def importCSV(csvPath, import2Table):\n",
    "#     import csv\n",
    "#     myTable = Base.metadata.tables[import2Table] #get table\n",
    "#     with open(csvPath, 'rt', encoding='utf-8-sig') as csvfile:\n",
    "#         csvreader = csv.reader(csvfile,dialect='excel')\n",
    "#             #also assume all header names match table field names\n",
    "#         headers = next(csvreader) #read csv headers to list\n",
    "#         #for each row, make a dictionary object of each column header:value pair (list comprehension of a dictionary comprehension)\n",
    "#         myRecDictLS = [{aheader:avalue for aheader, avalue in zip(headers,row)} for row in csvreader]\n",
    "#         print (myRecDictLS)\n",
    "#     session.execute(myTable.insert(),myRecDictLS)    #insert records into table\n",
    "#     session.commit()\n",
    "\n",
    "\n",
    "# importCSV('_jonhonda_files\\\\1_table_input.csv', 'people')\n",
    "\n",
    "\n",
    "# myRec = People(name = 'Jay', ssn = '4433032', age = 10)\n",
    "# session.add(myRec)\n",
    "# session.commit()\n",
    "# # myTable = Base.metadata.tables['users']\n",
    "# # myCol =  myTable.c['id']\n",
    "# # u=update(myTable)\n",
    "# # u=u.values({'fullname': 'Wendy Almon'})\n",
    "# # u.where(myCol.name == 2)\n",
    "# # session.execute(u)\n",
    "# # session.commit()\n",
    "# # for rec in session.query(myTable).filter(User.name == 'wendy'):\n",
    "# #     print (rec)\n",
    "\n",
    "# myTable = Base.metadata.tables['people']\n",
    "# myCol = myTable.c['name']\n",
    "# u = update(myTable)\n",
    "# u = u.values({'ssn':'Jane'})\n",
    "# u = u.where(myCol.name == 'Jon')\n",
    "# session.execute(u)\n",
    "# session.commit()\n",
    "\n",
    "# for rec in session.query(People):\n",
    "#     print (rec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inspect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-9228bb088608>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m \u001b[0mimportCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'_jonhonda_files\\\\2_table_input.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-9228bb088608>\u001b[0m in \u001b[0;36mimportCSV\u001b[1;34m(csvPath)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;31m#record primary keys inserted/updated during importing of csv row data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                     \u001b[1;31m#represent as a list of dicts {Table.PKName:PKid} for table of a given record. Each record is 1 element of list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mmyRecsLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_HELPER_importCSVrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheadersDict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCSVrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mCSVrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsvreader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m     \u001b[0m_HELPER_assocKEYS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyRecsLS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtablesLS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-9228bb088608>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[1;31m#record primary keys inserted/updated during importing of csv row data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m                     \u001b[1;31m#represent as a list of dicts {Table.PKName:PKid} for table of a given record. Each record is 1 element of list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mmyRecsLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_HELPER_importCSVrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheadersDict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCSVrow\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mCSVrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsvreader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m     \u001b[0m_HELPER_assocKEYS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyRecsLS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtablesLS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-9228bb088608>\u001b[0m in \u001b[0;36m_HELPER_importCSVrow\u001b[1;34m(headersDict, CSVrow, updateWhereLF)\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;31m#insert table and record's return primary key\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[0mmyTable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmyTableName\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m         \u001b[0mPKLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetPKFieldNames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyTable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#get primary key field for myTable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m         \u001b[0mPKCol\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mmyTable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mPKLS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#get sqlAlchemy object for PK Field\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mupdateWhereLF\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#force insert (update if PKid==-1234 which can't happen)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-9228bb088608>\u001b[0m in \u001b[0;36mgetPKFieldNames\u001b[1;34m(myTable)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \"\"\"  \n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mPKLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmyTable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mPKname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mPKname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minspect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyTable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#get Table.primary key using inspector. inspector requires iterator, so iterate pk into a list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mPKLS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#Use 1st element of list. split Table.FieldName. Return just fieldname pare\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inspect' is not defined"
     ]
    }
   ],
   "source": [
    "#import a single csv containing 2 or more tables. Tables can have PK-FK relations.\n",
    "#build SQLAlchemy objects, build DB:\n",
    "#connect to SQLite DB w/ SQLAlchemy ORM:\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "#deprecate working w/ dbs located on disk for now.\n",
    "# dbfilename = '_jonhonda_files//test.db' #right now code writes to memory, later change to write to disk not used right now.\n",
    "# print (\"\\nClearing old DB\")\n",
    "# try:\n",
    "#     os.remove(dbfilename)\n",
    "# except FileNotFoundError as err:\n",
    "#     print (\"no need to remove db file\")####it's okay if file doesn't exist. ####\n",
    "# engine = create_engine('sqlite:///'+ dbfilename, echo = False)\n",
    "\n",
    "#for now work w/ dbs in memory\n",
    "engine = create_engine('sqlite:///:memory:', echo = False)    \n",
    "\n",
    "#NOW DEFINE DB SCHEMA (THIS DOESN'T WRITE SCHEMA TO DB, JUST TO SQLALCHEMY CLASSES AND OBJECTS)\n",
    "#define an SQLAlchemy base class to maintain catalog of classes and tables relative to this base\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import MetaData\n",
    "Base = declarative_base()\n",
    "metadata = MetaData(bind=engine)\n",
    "\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "Session = sessionmaker(bind=engine) #define Session class, which is a factory for making session objects (poor naming choice, in my opinion - why the do it this way??!)\n",
    "session = Session() #make a session\n",
    "\n",
    "\n",
    "#use the base class to define mapped classes in terms of it:\n",
    "from sqlalchemy import Table, Column, Integer, String\n",
    "from sqlalchemy import update, insert\n",
    "from sqlalchemy import ForeignKey\n",
    "from sqlalchemy.orm import relationship #http://docs.sqlalchemy.org/en/latest/orm/basic_relationships.html#relationship-patterns    \n",
    "from sqlalchemy import in\n",
    "\n",
    "class People(Base):\n",
    "    __tablename__ = 'people'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String(50), unique=True)\n",
    "    ssn = Column(String(12))\n",
    "    age = Column(Integer)\n",
    "    locations = relationship(\"Locations\") #setup 1:many relationship. corresponds w/ people_id fk in Locations table\n",
    "       \n",
    "    def __repr__(self):\n",
    "        return \"<People(name='%s', ssn='%s', age='%s')>\" % (\n",
    "                                self.name, self.ssn, self.age)\n",
    "\n",
    "class Locations(Base):\n",
    "    __tablename__ = 'locations'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    city = Column(String(100))\n",
    "    country = Column(String(100))\n",
    "    people_id = Column(Integer, ForeignKey('people.id'))\n",
    " \n",
    "    def __repr__(self):\n",
    "        return \"<Locations(city='%s', country='%s', people_id='%s')>\" % (\n",
    "                            self.city, self.country, self.people_id)\n",
    "    \n",
    "#NOW WRITE SCHEMA TO DB (THIS WRITES TO SQLITE DB):\n",
    "Base.metadata.create_all(engine) #build DB schema from Base objects\n",
    "\n",
    "def getPKFieldNames (myTable):\n",
    "    \"\"\"Gets primary key field for the given table.\n",
    "    \n",
    "    Uses SQLAlchemy's .primary_key table attribute.\n",
    "    Since SQLAlchemy's .primary_key table attribut returns a list, we will use just the 1'st value\n",
    "    \n",
    "    Args:\n",
    "        myTable: the metadata.table that we want to insert/update on. \n",
    "\n",
    "    Returns\n",
    "        the primary key field as an integer\n",
    "        \n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"  \n",
    "    \n",
    "    PKLS = [myTable.name + '.' + PKname.key for PKname in inspect(myTable).primary_key] #get Table.primary key using inspector. inspector requires iterator, so iterate pk into a list\n",
    "    return PKLS[0].split('.')[1] #Use 1st element of list. split Table.FieldName. Return just fieldname pare\n",
    "    \n",
    "def insertupdateRec(myTable, setFieldVals, whereConstraint):\n",
    "    \"\"\"Inserts or updates values into a table's fields subject to some constraints.\n",
    "\n",
    "    Only works on one record row at a time. So only pass in 1 record's args\n",
    "    \n",
    "    Args:\n",
    "        myTable: the metadata.table that we want to insert/update on. \n",
    "        setFieldVals: a single record represented as a dictionary of fields\n",
    "                    and values to be inserted/updated {fieldname:val, fieldname:val}                     \n",
    "        whereConstraint: where clause used to determine if record already exists/update on\n",
    "                    passed in as a lambda function\n",
    "\n",
    "    Returns\n",
    "        the primary key id value of the table we updated/inserted to. \n",
    "        primary key is returned as an integer.\n",
    "\n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"  \n",
    "\n",
    "    PKName = getPKFieldNames(myTable) #shove parts of this into getPKFieldNames\n",
    "    ret = session.query(myTable.c[PKName]).filter(whereConstraint) #determine existance of record w/ whereConstraint\n",
    "    exist=False\n",
    "    PKid = -1234\n",
    "    \n",
    "    #below for-if/then logic can be replaced w/\n",
    "    #if not ret[0] then no rec exists\n",
    "    \n",
    "    #else then rec exists\n",
    "    \n",
    "    for r in ret:\n",
    "        exist=True\n",
    "        PKid = r[0]\n",
    "        break\n",
    "    if exist:#record exists. update it\n",
    "        updateRec(myTable, setFieldVals, whereConstraint)\n",
    "#         print('update')\n",
    "    else: #record DNE. insert it\n",
    "        PKid = insertRec(myTable, setFieldVals)\n",
    "#         print ('insert')\n",
    "    return PKid\n",
    "        \n",
    "def insertRec(myTable, setFieldVals):\n",
    " #insert a single record:\n",
    "        #ex: insertRec(FkTable, {FkFKField.name:arecPKid})\n",
    "        #updateTable: table to update\n",
    "        #setFieldVals: dictionary of fields and vals to be updated: {fieldname:val,fieldname:val}\n",
    "    rec = session.execute(myTable.insert(),setFieldVals)\n",
    "    return rec.inserted_primary_key[0]\n",
    "\n",
    "def updateRec(updateTable, setFieldVals, updateWhereLF):\n",
    "    #update a single records:\n",
    "        #ex: updateRecs(FkTable, {FkFKField.name:arecPKid}, (lambda x,y: x == y)(FkPKField, constrVal))\n",
    "        #updateTable: table to update\n",
    "        #setFieldVals: dictionarinserted_proimary_key[0]y of fields and vals to be updated: {fieldname:val,fieldname:val}\n",
    "        #updateWhereLF: update constraints where constraint, passed as a lambda function, is true  \n",
    "    u = update(updateTable)\n",
    "    u = u.values(setFieldVals)\n",
    "    u = u.where(updateWhereLF)\n",
    "    rec = session.execute(u)\n",
    "\n",
    "def _HELPER_importCSVrow(headersDict, CSVrow, updateWhereLF = False):\n",
    "    #importCSV helper function to handle inserting a single CSV row\n",
    "    #currently forces insert (will be changed to discriminate based on existance of record using lambda function)\n",
    "        #headersDict: dictionary of form: {table.field:[table,field]}\n",
    "        #CSVrow: single row of a csv reader loop\n",
    "        #updateWhereLF:where Clause as a lambda function to pass to insert/updater to determinE record existance\n",
    "                        #False to force insert\n",
    "    #return primary keys inserted/updated using CSVrow values\n",
    "    C_TABLE = 0 #header 0th element is table name\n",
    "    C_FIELD = 1 #header 1st element is field name    \n",
    "    myTempRecDicts = {aheader[C_TABLE]:{} for aheader in headersDict.values()} #initialize dictionary of tables #and their associated list of  records. note the empty dict. needed b/c we will update that empty dict\n",
    "    for aheader, avalue in zip(headersDict.values(),CSVrow): #write current header-value pair to a temp dictionary \n",
    "        mytmpDict = {aheader[C_FIELD]:avalue}\n",
    "        myTempRecDicts[aheader[C_TABLE]].update(mytmpDict) #place temp dictionary value into current rec's dictionary of tables an assoc. header-values\n",
    "    myRowRecDict={} #dictionary of record ids inserted/updated for current row: {PKName:PK_ID}\n",
    "    for myTableName,myRecDict in myTempRecDicts.items(): \n",
    "        #insert table and record's return primary key\n",
    "        myTable = Base.metadata.tables[myTableName]\n",
    "        PKLS = getPKFieldNames(myTable)#get primary key field for myTable\n",
    "        PKCol =myTable.c[PKLS[0].split('.')[1]] #get sqlAlchemy object for PK Field\n",
    "        if updateWhereLF==False:#force insert (update if PKid==-1234 which can't happen)\n",
    "            rec_id = insertupdateRec(myTable, myRecDict, (lambda PKid: PKid == -1234)(PKCol)) \n",
    "#         else:\n",
    "#             rec_id = insertupdateRec(myTable, myRecDict, (lambda PKid: PKid == -1234)(PKCol))             \n",
    "        myRowRecDict.update({PKLS[0]:rec_id}) #add PK id to record of rows added     \n",
    "    return myRowRecDict\n",
    "\n",
    "def _HELPER_assocKEYS(myRecsLS, tablesLS):\n",
    "    #helper function to associate primary-foreign key pairings during importCSV of mixed tables:\n",
    "     #find PK-FK links between tables    \n",
    "    PkFkLS = [] #init empty pk-fk list, of assumed form: [[PKTable.PKCOL,FKTable.FKCol],[PKTable.PKCOL,FKTable.FKCol],...]\n",
    "    for myTable in tablesLS:\n",
    "        for col in Base.metadata.tables[myTable].c:\n",
    "            if col.foreign_keys:PkFkLS.append([str(list(col.foreign_keys)[0].column),str(col)])\n",
    "    C_PK=0\n",
    "    C_FK=1\n",
    "    C_TABLE = 0 #header 0th element is table name\n",
    "    C_FIELD = 1 #header 1st element is field name    \n",
    "    #update the foreign key id for each PK-FK relationship affected by csv row data import:\n",
    "    for aRec in myRecsLS:\n",
    "        for aPkFk in PkFkLS:\n",
    "            arecPKid=-1234\n",
    "            if aPkFk[C_PK] in aRec: #if current PkFk pair is part of aRec then\n",
    "            #update FK_TABLE SET FK_ID = xxx WHERE FK_TABLE'S PK = XXX \n",
    "            #get data we need:\n",
    "                FkLS = aPkFk[C_FK].split('.') #make [tablename, fieldname] of the Table-Field holding the Fk we want to update \n",
    "                FkTable = Base.metadata.tables[FkLS[C_TABLE]] #assign foreign key table\n",
    "                FkFKField = FkTable.c[FkLS[C_FIELD]] #assign FK table's FK field\n",
    "                FkPKFieldName = [PKname.key for PKname in inspect(FkTable).primary_key][0] #get FK Table.primary key using inspector. inspector requires iterator, so iterate pk into a list                \n",
    "                FkPKField = FkTable.c[FkPKFieldName] #assign FK table's PK field\n",
    "                arecPKid = aRec[aPkFk[C_PK]] #get PKid for aRec[aPkFk] corresponding to current aPkFk's PK name\n",
    "            #now build updater:\n",
    "                constrVal = aRec[FkTable.name + '.' + FkPKField.name]\n",
    "                updateRec(FkTable, {FkFKField.name:arecPKid}, (lambda x,y: x == y)(FkPKField, constrVal))    \n",
    "\n",
    "def importCSV(csvPath):\n",
    "    #assume header given in form: tablename.fieldname\n",
    "    # assume all table and header names match database table and field names\n",
    "    import csv\n",
    "    C_TABLE = 0 #header 0th element is table name\n",
    "    C_FIELD = 1 #header 1st element is field name\n",
    "    with open(csvPath, 'rt', encoding='utf-8-sig') as csvfile:\n",
    "        csvreader = csv.reader(csvfile,dialect='excel')\n",
    "        rawheadersLS = next(csvreader) #read raw csv headers to list\n",
    "        headersDict = {myheader:myheader.split('.') for myheader in rawheadersLS} #collect rawheader (Table.FieldName) and its table & field compenent\n",
    "        #make list of tables:\n",
    "        tablesLS=[]\n",
    "        for aheader in headersDict.values():\n",
    "            if aheader[C_TABLE] not in tablesLS:\n",
    "                tablesLS.append(aheader[C_TABLE])\n",
    "        #record primary keys inserted/updated during importing of csv row data. \n",
    "                    #represent as a list of dicts {Table.PKName:PKid} for table of a given record. Each record is 1 element of list       \n",
    "        myRecsLS = [_HELPER_importCSVrow(headersDict,CSVrow) for CSVrow in csvreader]\n",
    "    _HELPER_assocKEYS(myRecsLS, tablesLS)\n",
    "    session.commit()\n",
    "    for myTable in tablesLS: #query data to show results\n",
    "        for rec in session.query(Base.metadata.tables[myTable]):\n",
    "            print (rec)\n",
    "            \n",
    "importCSV('_jonhonda_files\\\\2_table_input.csv')    \n",
    "session.close()    \n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "12\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#play with functional programming - inscope functions and lambda functions:\n",
    "\n",
    "#define an inscope function:\n",
    "def High(a):\n",
    "    def low(a):return a+1    \n",
    "    return low(a)+2\n",
    "print (str(High(0)))\n",
    "\n",
    "#use lambda functions\n",
    "def f1(passedFunc):\n",
    "    print (passedFunc)\n",
    "def main():\n",
    "    f1((lambda x, y: x * y)(3,4))\n",
    "    f1((lambda x: x **2)(3))\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
