{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Michael Allen Project 1\n",
    "#### [11/09/2017] | [Michael Allen] | [Sprint 1]\n",
    "#### Description\n",
    "To gather data which highlights many variables that may come into play when a participant fills out a given survey.  \n",
    "To create a Version 1.0 \"End of Sprint Survey\" in order for data simulation purposes only.  To look at the Data in both \n",
    "CSV and R file formats.    Test with Ben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gameplan\n",
    "Here is my overall Game Plan\n",
    "\n",
    "1. Investigate and document potential bias for survey data\n",
    "2. Create Version 1.0 \"End of Sprint Survey\" in Survey Monkey\n",
    "3. Analyze output in Survey Monkey\n",
    "4. Export to Excel\n",
    "5. Investigate if it can be exported to Excel\n",
    "6. Convert Excel to R\n",
    "7. Look at Survey data in CSV, illustrate and annotate with concepts\n",
    "8. Look at Survey data in R illustrate and annotate\n",
    "9. Create CSV Mind mapping concepts\n",
    "10. Create R Mind mapping concepts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Gameplan\n",
    "1. Create Version 1.0 \"End of Sprint Survey\" in Survey Monkey:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Question_1_thru_4.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Question_5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Question_6_thru_8.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Question_9_thru_10.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Gameplan\n",
    "Here is my overall approach\n",
    "\n",
    "1. Create Version 1.0 \"End of Sprint Survey\" in Survey Monkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Michael Allen Project 1\n",
    "#### [11/09/2017] | [Michael Allen] | [Sprint 1]\n",
    "#### Description\n",
    "To gather data which highlights many variables that may come into play when a participant fills out a given survey.  To create a Version 1.0 \"End of Sprint Survey\" in order for data simulation purposes only.  To look at the Data in both CSV and R file formats.    \n",
    "\n",
    "## Skill Backlog User Story\n",
    "\n",
    "## Project Proposal Sprint 1 - As a Technology Teacher: I need to understand the basic terminology and structure of data so that I can apply statistical analyses. I also need to understand the story of where the data came from so I know how it is relevant to my action or recommendation.\n",
    "\n",
    "An overall User Story: As a [Technology Teacher] I need [Understand the basics of Big Data] so that [I can show and convey it to others. \n",
    "\n",
    "I propose to first document potential bias from particants on filling out a survey as well as the researcher design biases for the survey tool.  This is useful to understand the story of where the data came from so I know how it is relevant to my action or recommendations.  Secondly to create a quick \"End of Sprint Survey\" in Survey Monday, and then where I will first simulate completing multiple surveys. Survey Monkey has immediate analysis (though I do not know in what format this is in.  I believe I can then export to Excel.  Where then I will look into how to convert it to \"R\" in order to learn this program in subsequent Sprints for equal or better analysis then what Excel offers.  \n",
    "\n",
    "### Five Pitches for the 11/08/2017 Session for Sprint Number 1\n",
    "1. In Survey Monkey, create a quick Version 1.0 \"End of Sprint Survey\" so that all of us in the BDA Cohort can evaluate and give feedback to Ben and DevLeague for how Sprint 1 and all the subsequent Sprints went.  Sprint 1 will be to look at the how the data went from conception to an output in Survey Monkey (what kind of data is this) or Excel (maybe at this time). Perhaps another program (\"R\") in a future Sprint.\n",
    "\n",
    "2. Take existing \"End of Course Survey\" data which is in Excel and begin to look at it in \"R\".\n",
    "\n",
    "3. Currently I have a home for sale in Ko Olina and have been sent an email link with a statistic stating as of today 10,158 people have seen my ad.  What does this really mean?  Where is the data coming from?\n",
    "\n",
    "4. A z-score (aka, a standard score) indicates how many standard deviations an element is from the mean. A z-score can be calculated from the following formula. z = (X - μ) / σ where z is the z-score, X is the value of the element, μ is the population mean, and σ is the standard deviation.  Where does this data come from?  What might be a good program for analyzing it?\n",
    "\n",
    "5. What data do Real Estate Agents on Oahu utilize in order to determine where to spend advertising dollars for thier listings?\n",
    "\n",
    "## Key Questions\n",
    "What is the story of where the data came from?  Who filled it out?  Why are they there in the first place.  Forced.  Initiated.  What does the completed Survey Data look like in CSV and R file Formats.\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Day 1 Work\n",
    "\n",
    "This is what I tried to do on Day 1. \n",
    "\n",
    "(Document potential bias from particants on filling out a survey)\n",
    "1. Knowledgeable enough to be attending\n",
    "2. Experience\n",
    "3. Gender\n",
    "4. Age\n",
    "5. In a rush to complete survey (not built-in time to fill it out)\n",
    "6. Had a bad morning at home/hotel that day.\n",
    "7. Bad traffic day\n",
    "8. Not focused during the course\n",
    "9. Did not do required work throughout the course\n",
    "10. Relationship issues at home/work\n",
    "11. Past / present working/personal relationship with Instructor\n",
    "12. Motivation\n",
    "13. Forced to attend\n",
    "14. Job depends on success of course understanding and completion\n",
    "\n",
    "*Design Bias - Introduction of errors:\n",
    "Undercoverage. Undercoverage occurs when some members of the population are inadequately represented in the sample. A classic example of undercoverage is the Literary Digest voter survey, which predicted that Alfred Landon would beat Franklin Roosevelt in the 1936 presidential election. The survey sample suffered from undercoverage of low-income voters, who tended to be Democrats.\n",
    "How did this happen? The survey relied on a convenience sample, drawn from telephone directories and car registration lists. In 1936, people who owned cars and telephones tended to be more affluent. Undercoverage is often a problem with convenience samples.*\n",
    "\n",
    "*• Nonresponse bias. Sometimes, individuals chosen for the sample are unwilling or unable to participate in the survey. Nonresponse bias is the bias that results when respondents differ in meaningful ways from nonrespondents. The Literary Digest survey illustrates this problem. Respondents tended to be Landon supporters; and nonrespondents, Roosevelt supporters. Since only 25% of the sampled voters actually completed the mail-in survey, survey results overestimated voter support for Alfred Landon.\n",
    "The Literary Digest experience illustrates a common problem with mail surveys. Response rate is often\n",
    "low, making mail surveys vulnerable to nonresponse bias.*\n",
    "\n",
    "• *Voluntary response bias. Voluntary response bias occurs when sample members are self-selected\n",
    "volunteers, as in voluntary samples. An example would be call-in radio shows that solicit audience participation in surveys on controversial topics (abortion, affirmative action, gun control, etc.). The resulting sample tends to overrepresent individuals who have strong opinions.\n",
    "Random sampling is a procedure for sampling from a population in which (a) the selection of a sample unit is based on chance and (b) every element of the population has a known, non-zero probability of being selected. Random sampling helps produce representative samples by eliminating voluntary response bias and guarding against undercoverage bias. All probability sampling methods rely on random sampling.*\n",
    "\n",
    "Response bias refers to the bias that results from problems in the measurement process. Some examples of response bias are given below.\n",
    "\n",
    "• *Leading questions. The wording of the question may be loaded in some way to unduly favor one response over another. For example, a satisfaction survey may ask the respondent to indicate where she is satisfied, dissatisfied, or very dissatified. By giving the respondent one response option to express satisfaction and two response options to express dissatisfaction, this survey question is biased toward getting a dissatisfied response.\n",
    "• Social desirability. Most people like to present themselves in a favorable light, so they will be reluctant to admit to unsavory attitudes or illegal activities in a survey, particularly if survey results are not confidential. Instead, their responses may be biased toward what they believe is socially desirable.*\n",
    "\n",
    "*Acquiescence bias, which is also referred to as \"yea-saying\", is a category of response bias in which respondents to a survey have a tendency to agree with all the questions in a measure. This bias in responding may represent a form of dishonest reporting because the participant automatically endorses any statements, even if it results in contradictory responses.[16][17] For example, a participant could be asked whether they endorse the following statement, \"I prefer to spend time with others\" but then later on in the survey also endorses \"I prefer to spend time alone,\" which are contradictory statements. This is a distinct problem for self-report research because it does not allow a researcher to understand or gather accurate data from any type of question that asks for a participant to endorse or reject statements.[16] Researchers have approached this issue by thinking about the bias in two different ways. The first deals with the idea that participants are trying to be agreeable, in order to avoid the disapproval of the researcher.*\n",
    "\n",
    "*Subject bias, also known as participant bias, is a tendency of participants (subjects) in an experiment to consciously or subconsciously act in a way that they think the experimenter/researcher wants them to act. It often occurs when subjects realize or know the purpose of the study.*\n",
    "\n",
    "*1. Social Desirability & Conformity*\n",
    "\n",
    "*Don’t you agree that recycling is an important initiative for companies to embrace?*\n",
    "\n",
    "*Approximately how much time do you spend reading to your children each night?*\n",
    "\n",
    "*On average, how much time do you spend planning meals for your family?*\n",
    "\n",
    "*If it’s socially acceptable (recycling, reading to kids, or caring for your family), respondents are much more likely to endorse and exaggerate. In additional to socially desirable, a number of studies show people will conform to group norms[pdf] both offline and online.*\n",
    "\n",
    "*In fact, it’s hard to convince respondents to go against what’s acceptable even when things are clearly bizarre[pdf]. This means respondents will have a propensity to provide the socially acceptable response over the true response.*\n",
    "\n",
    "*2. Yea Saying and Acquiescing*\n",
    "\n",
    "*Do you want your coffee machine to have different profiles?*\n",
    "\n",
    "*Do you use the mail merge feature of Word?*\n",
    "\n",
    "*Respondents can tend to be agreeable (acquiesce) and respond usually positively to just about any question you ask them in a survey. One of the best way to minimize this “yea” saying is to minimize simple yes-no answers and instead have respondents select from alternatives or use some type of force choice or ranking.*\n",
    "\n",
    "*Note: While a common solution to minimize acquiescent bias is to reverse the tone of items in rating scales, we’ve found, along with other research, that reversing the item wording can actually cause more harm than good in rating scales.*\n",
    "\n",
    "*3. Order Effects*\n",
    "\n",
    "*The order you ask questions matters. Mentioning products, brands, or events can affect how people rate their familiarity and attitudes on subsequent questions. This can be especially harmful in branding and awareness surveys as the mere exposure of a brand name first can influence later questions and findings.  Response options also matter. A respondent might remember a choice that appeared in an earlier question and be more likely to select the response on later questions.  You can often manage many order effects through properly sequenced questions and randomization.*\n",
    "\n",
    "*4. Prestige*\n",
    "\n",
    "*How much influence do you have on IT purchase decisions at your company?*\n",
    "\n",
    "*What’s your income and highest level of education?*\n",
    "\n",
    "*Respondents will likely round up on income (especially men), education, and their reported power and prestige when making decisions. This is different than outright lying or cheating on a survey. If a question asks about prestige, assume the responses are inflated to present the respondent in a more favorable light. Exactly how much they are inflated will depend on the question, context and respondents.*\n",
    "\n",
    "*5. Threat & Hostility*\n",
    "\n",
    "*Think about the last time you were in a car accident. Did you access the insurance company’s mobile app?*\n",
    "\n",
    "*Getting people to think about unpleasant things and events can get them in the wrong state of mind, which can cast a negative shadow on subsequent questions. Studies have shown getting people in a hostile mindset will affect their attitudes[pdf], and consequently survey responses.*\n",
    "\n",
    "*Even rather benign questions (like asking people their marital status) may prime respondents with negative thoughts as participants recall bad past experiences (like a divorce or death in the family). Moving more sensitive demographic questions and anything that could potentially elicit negative thoughts to the end of a survey when possible may help.*\n",
    "\n",
    "*6.  Sponsorship*\n",
    "\n",
    "*When respondents know where the survey is coming from (the sponsor), it will likely influence responses. If you know the questions about your online social media experience are coming from Facebook, your thoughts and feelings about Facebook will likely impact responses.*\n",
    "\n",
    "*This can be especially the case for more ethereal measures like brand attitude and awareness that can be affected from the mere reminder of a brand in the email invitation or name and logo on the welcome page. One of the best ways to minimize sponsorship bias is to obfuscate the sponsor as much as possible and/ or use a third-party research firm (shameless self-promotion).*\n",
    "\n",
    "*7. Stereotype*\n",
    "\n",
    "*Asking about gender, race, technical ability, education, or other socio-economic topics may reinforce stereotypes in the mind of the respondents and may even lead them to act in more stereotypical ways. For example, reminding people that stereotypes exist around those who are more technically averse (age), math ability (gender), or intelligence (education level) may affect later responses as the stereotype primes respondents through the questions.*\n",
    "\n",
    "*8. Mindset (Carry-Over Effects)*\n",
    "\n",
    "*Thinking about the last time you moved, how many items did you list on craigslist?*\n",
    "\n",
    "*Overall, how satisfied are you with the craigslist website?*\n",
    "\n",
    "*It’s likely the response to the second question above is affected by the mindset of the initial question (moving). Rating the experience of moving and using craigslist during the move in the first question will likely have an impact when respondents mentally switch to the second broader question about craigslist in general. It’s likely respondents may still be thinking of how they used craigslist during their move even if you don’t intend them to.*\n",
    "\n",
    "*These mindset biases can sometimes be offset by managing the order, but often can’t be avoided entirely if you’re getting respondents to consider multiple mindsets in the same survey.*\n",
    "\n",
    "*9. Motivated Forgetting*\n",
    "\n",
    "*After you saw the iPhone commercial for the first time, how long was it until you purchased one?*\n",
    "\n",
    "*Memories are malleable and in general, we’re not terribly good at remembering events accurately.  People tend to distort their memories to match current beliefs, also called telescoping. Respondents may recall an event but report that it happened earlier than it actually did (backward telescoping) or report that it happened more recently (forward telescoping).*\n",
    "\n",
    "*Many research questions rely on participants to recall specific events or behavior. There can be a tendency to recall events that didn’t happen or forget the specifics of an event.\n",
    "Bias Doesn’t Necessarily Mean Garbage*\n",
    "\n",
    "*Just because a survey has bias doesn’t mean the results are meaningless. It does mean you should be able to understand how each may impact your results. This is especially important when you’re attempting to identify the percentage of a population (e.g. the actual percent that agree to statements, have certain demographics like higher income, or their actual influence on purchase decisions).*\n",
    "\n",
    "*While there’s not a magic cure for finding and removing all biases, being aware of them helps limit their negative impact. A future article will discuss some ideas for how to identify and reduce the effects of biases and other common pitfalls in survey design.*\n",
    "\n",
    "*Question Wording*\n",
    "\n",
    "*Survey bias can be subtle or blatantly obvious in a question’s wording, and can take many forms. It is the survey designer’s job to remain impartial and avoid writing questions that lead or confuse the respondent. This is usually easier said than done as writers generally create biased questions due to their own lack of knowledge in a subject or ignorance of other people’s perspective on that subject.\n",
    "To help squash this bias, it is essential to remain neutral in all questions no matter how extreme the topic. It also helps to conduct secondary research to ensure you have a full understanding of the topic in study. Furthermore, a constructive peer review by an expert in the same field of the survey topic will allow you to learn of any problems with your questions that make them confusing or erroneous for the subject of study and its target population.\n",
    "Beyond this, there are several rules that survey creators should always abide by when writing survey questions. Learn them all and reduce your survey bias by reviewing ‘Get the Most Out of Your Survey: Tips for Writing Effective Questions‘.\n",
    "Question Type and Design*\n",
    "\n",
    "*This type of survey bias includes the selection of different forms of questions (rating scales, ranking, open-ended versus closed-ended) and the options of answers provided to the respondent. The selections made in question types can have significant impact on the responses received. This is also the case for the options researchers provide for participants to choose from.\n",
    "To avoid running into this type of bias, it is crucial for the researcher to understand the strengths and weaknesses of each question type they will be using. This way the question and its options will not only be chosen correctly but can be tailored in order to provide only the most useful data. For more information on how to use different question types check out FluidSurveys’s video tutorials.\n",
    "Survey Structure*\n",
    "\n",
    "*One of the most overlooked forms of survey bias comes from poorly designed survey structures. Survey structure usually pertains to the order in which the survey questions are revealed to the respondent, but can also refer to the number of questions per page, the survey logic, the survey length, and the introduction and conclusion. Each of these portions of survey structure can contribute to survey bias and drop outs.\n",
    "As with the other forms of survey bias, the best way to avoid making errors with your survey structure is through studying how modifying each aspect of your survey will affect your respondents’ reactions to each question. For example, putting the most threatening or personal seeming questions at the end of your survey will decrease your number of drop outs. Acknowledging information like this will allow you to construct the best possible surveys.*\n",
    "\n",
    "*1.  Researcher Bias.\n",
    "\n",
    "The most important error that creeps into surveys about isn’t statistical at all and is not measurable. The viewpoint of the researcher has a way of creeping into question design and analysis. Some times this is purposeful, and other times it is more subtle. All research designers are human, and have points-of-view. Even the most practiced and professional researchers can have subtle biases in the way they word questions or interpret results. How we frame questions and report results is always affected by our experiences and viewpoints – which can be a good thing, but can also affect the purity of the study.*\n",
    "\n",
    "*2. Poor match of the sample to the population.*\n",
    "\n",
    "*This is the source of some of the most famous errors in polling. Our industry once predicted the elections of future Presidents Alf Landon and Thomas Dewey based on this mistake. It is almost never the case that the sampling frame you use is a perfect match to the population you are trying to understand, so this error is present on most studies. You can sometimes recover from asking the wrong questions, but you can never recover from asking them of the wrong people*\n",
    "\n",
    "*Most clients (and suppliers) like to focus on questionnaire development when a new project is awarded. The reality is the sampling and weighting plan is every bit as consequential to the success of the project, and rarely gets the attention it deserves. We can tell when we have a client that really knows what they are doing if they begin the project by focusing on sampling issues and not jumping to questionnaire design.*\n",
    "\n",
    "*3. Lack of randomness/response bias.*\n",
    "\n",
    "*Many surveys proceed without random samples. In fact, it is rare that a survey being done today can accurately claim to be using a random sample. Remember those statistics courses you took in college and graduate school? The one thing they have in common is pretty much everything they taught you statistically is only relevant if you have a random sample. And, odds are great that you don’t.*\n",
    "\n",
    "*A big source of “non-randomness” in a sample is response bias. A typical RDD phone survey being conducted today has a cooperation rate of less than 20%. 10% is considered a good response rate from an online panel. When we report results of these studies, we are assuming that the vast majority of people who didn’t respond would have responded in the same way as those who did. Often, this is a reasonable assumption. But, sometimes it is not. Response bias is routinely ignored in market research and polls because it is expensive to correct (the fix involves surveying the non-responders).*\n",
    "\n",
    "*4.  Failure to quota sample or weight data.*\n",
    "\n",
    "*This is a bit technical. Even if we sample randomly, it is typical for some subgroups to be more willing to cooperate than others. For example, females are typically less likely to refuse a survey invitation than males, and minorities are less likely to participate than whites. So, a good researcher will quota sample and weight data to compensate for this. In short, if you know something about your population before you survey them, you should use this knowledge to your advantage. If you are conducting an online poll and you are not doing something to quota sample or weight the data, odds are very good that you are making an important mistake.*\n",
    "\n",
    "*5.  Overdoing it.*\n",
    "\n",
    "*I have worked with methodologists who have more degrees than a thermometer, think about the world in Greek letters, and understand every type of bias we can comprehend. I have also seen them concentrate so much on correcting for every type of error they can imagine that they “overcook” the data. I remember once passing off a data set to a statistician, who corrected for 10 types of errors, and the resulting data set didn’t even have the gender distribution it the proper proportion.*\n",
    "\n",
    "*Remember — you don’t have to correct for an error or bias unless it has an effect on what you are asking.  For example, if men and women answer a question identically, weighting by gender will have no effect on the study results. Instead, you should know enough about the issues you are studying to know what types of errors are likely to be relevant to your study.*\n",
    "\n",
    "*So that is our top 5. Note that I did not put sampling error in the top 5. I am not sure it would make my top 20. Sampling error is the “+/- 5%” that you see attached to many polls. We will do a subsequent blog post on why this isn’t a particularly relevant error for most studies. It just happens to be the one type of error that can be easily calculated mathematically, which is why we see it cited so often. I am more concerned about the errors that are harder to calculate, or, more importantly, the ones that go unnoticed.*\n",
    "\n",
    "*With 40+ sources of errors, one could wonder how our industry ever gets it right. Yet we do. More than $10 Billion is spent on research and polling in the US each year, and if this money was not being spent effectively, the industry would implode. So, how do we get it right?*\n",
    "\n",
    "*In one sense, many of the errors in surveys tend to be randomly distributed. For instance, there can be a fatigue bias in a question involving a long list of items to be assessed. By presenting long lists in a randomized order we can “randomize” this error – we don’t remove it.*\n",
    "\n",
    "*In some sense, errors and biases also seem to have a tendency to cancel each other out, rather than magnify each other. And, as stated above, not all errors matter to every project. The key is to consider which ones might before the study is fielded.*\n",
    "\n",
    "## Peer Feedback on Day 2\n",
    "\n",
    "To investigate the story of where the data came from in the first place. What potential bias exists when a participant fills out a survey.  Where are they coming from in the first place.  Who are they? And what is the ultimate goal of the designer of the survey?  Evaluate the program, the Instructor, the Institition, Marketing, Profit/Loss, \n",
    "\n",
    "\n",
    "## Day 3 Work\n",
    "Notes on starting to work with R.\n",
    "\n",
    "previously needed to setwd()\n",
    "\n",
    "getwd()\n",
    "[1] \"C:/Users/micha/Desktop/DevLeague Begins Nov 7 2017\"\n",
    "> read.csv(\"Dev League Slack Analytics Nov 05 2017.xls\")\n",
    "\n",
    "getwd()\n",
    "[1] \"C:/Users/micha/Documents\"\n",
    "> setwd(\"C:/Users/micha/Desktop/DevLeague Begins Nov 7 2017/\")\n",
    "> getwd()\n",
    "[1] \"C:/Users/micha/Desktop/DevLeague Begins Nov 7 2017\"\n",
    ">\n",
    "To declare a variable:\n",
    "\n",
    " surveys = read.csv(\"Simulated Survey Data II/CSV/Mock Survey Data.csv\")\n",
    "\n",
    "> surveys  (then the variable \"surveys\" will have the data from \"Mock Survey Data\"\n",
    "\n",
    "Weekend Work\n",
    "\n",
    "Created a Ten Question Survey in Survey Monkey (Any more than 10 Questions requires a paid subscription)and uploaded the PDF file \"Survey Questions to Generate Data in Survey Monkey\" will be uploaded to GitHub Projects\n",
    "\n",
    "\n",
    "Survey Monkey Link for the canned survey\n",
    "https://www.surveymonkey.com/r/JKZJGNW\n",
    "\n",
    "Survey Monkey Link for more appropriate Survey though only 10 questions\n",
    "https://www.surveymonkey.com/r/36B9SNC\n",
    "\n",
    "Then after manually filling out 21 surveys, through survey monkey I can see thier analysis, but not allowed to export to Excel or any other program without a paid subscription either.\n",
    "\n",
    "Created a third survey using another account:\n",
    "https://www.surveymonkey.com/r/H5TQNZ7\n",
    "\n",
    "read.csv(\"Simulated Survey Data II/CSV/Mock Survey Data.csv\") - it Works...!!!\n",
    "\n",
    "Then went back to the Excel Survey Monkey Data that I had exported and replaced Strongly Agree with \"40\", Agree with \"30\", Disagree with \"20\" and Strongly Disagree with \"10\".  (These I will b calling the Mean Perceived Learning Scores (MPLS) in future weeks.)\n",
    "\n",
    "\n",
    "## Here are some overall notes on the skills I learned\n",
    "And perhaps some stream of consciousness notes about what I did, and other questions I might have\n",
    "\n",
    "(Tori and John - Thanks..! for the GitHub help)\n",
    "\n",
    "This is the code to copy a image: (actually look at my email for this as when I show it, it is executing at the moment)  the image needs to be in the proper directory  and BE SURE the FILE says MARKDOWN\n",
    "\n",
    "## Gameplan 7. Survey data in CSV illustrated and annotated with concepts\n",
    "Here is the image showing that.\n",
    "\n",
    "## Gameplan 8. Survey data in R illustrated and annotated with concepts\n",
    "Here is the image showing that.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](CSV_Data_illustrated.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Gameplan 8. Survey data in R illustrated and annotated with concepts\n",
    "Here is the image showing that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Page1_R_Data_illustrated.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Page2_R_Data_illustrated.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Page3_R_Data_illustrated.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Page4_R_Data_illustrated.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Gameplan\n",
    "9. CSV Mind mapping concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Page1_CSV_Mind_Mapping_Data.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Page2_CSV_Mind_Mapping_Data.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Gameplan\n",
    "10. R Mind mapping concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Page1_R_Mind_Mapping_Data.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Page2.0_R_Mind_Mapping_Data.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Page3_R_Mind_Mapping_Data.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Page4_R_Mind_Mapping_Data.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Final document on Wednesday"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
