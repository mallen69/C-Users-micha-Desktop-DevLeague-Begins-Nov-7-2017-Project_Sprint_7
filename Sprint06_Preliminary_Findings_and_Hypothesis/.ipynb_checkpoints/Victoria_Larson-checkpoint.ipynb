{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preliminary Findings and Hypotheses Sprint Journal for Victoria Larson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 (Week 1): Pair EDA and Concept Demonstration\n",
    "\n",
    "### 1. Exploratory Data Analysis Concepts to use or test on this project\n",
    "concepts, definitions, why you are interested or think they will be useful. These are the concepts you will illustrate in the sections below. Recommend selecting 3-5, but choose as many as you think you can explore comprehensively.\n",
    "\n",
    "### 2. Professionally Relevant Datasets\n",
    "Find a dataset that would be useful for you to become more familiar with professionally. Can identify multiple (max 3 recommended)\n",
    "\n",
    "### 3. EDA Steps for your partner to explore your dataset(s)\n",
    "The first part of this sprint project will be to trade datasets with a partner. The idea for the exercise is to think about what you think might be interesting about a dataset and create an EDA plan to explore it. Except the first pass will be for your partner to carry out your EDA plan and report back to you with preliminary findings.\n",
    "\n",
    "Create a new Jupyter notebook (python or R) that loads your dataset and includes cells for the steps you want your partner to take and empty cells for the code to complete them as well as empty cells where preliminary findings should go.\n",
    "\n",
    "### 4. Carrying out your Partner's EDA Steps\n",
    "Complete the EDA process notebook your partner created\n",
    "\n",
    "### 5. Applying your EDA Concepts (step 1) to your partner's dataset. \n",
    "Use your partner's dataset as a basis to explore the concepts for this week\n",
    "\n",
    "## Part 2 (Week 2): EDA of your Dataset\n",
    "Walk through a polished Exploratory Data Analysis exercise in your personal repo. This can include the steps that you laid out originally, any new steps and new ideas you have, or any new techniques you developed from the concepts in (5.) above. \n",
    "\n",
    "Your final deliverable repo should include a \n",
    "- 1.) readme and a script file OR\n",
    "- 2.) a notebook \n",
    "\n",
    "that illustrates your analysis and leads to preliminary findings and hypotheses about the dataset for future investigation or more thorough analysis.\n",
    "\n",
    "## Day three notes:\n",
    "On day three we switched gears a little bit and Michael and I worked on how to do webscraping and parsing. We were using data from http://livingwage.mit.edu/ , which shows different wages per county in each state. I found the Occupaitional wages the most interesting so I wanted to stick with that table to parse and I use Weber County in Utah to parse the data from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Day four notes:\n",
    "To expand upon day three I finally figured out how to do this function. Hallelujah! Code Below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 1 - Get the State URL by just typing in a Number\n",
    "state_url_from_num = function(state_num) {\n",
    "  state_url = paste(\"http://livingwage.mit.edu/states/\",state_num, sep = \"\")\n",
    "  return(state_url)\n",
    "}\n",
    "\n",
    "# Step 2 - Get the occupation table by typing in the the state URL into the argument.\n",
    "get_occ_table_from_url = function(state_url) {\n",
    "  #state_url = \"http://livingwage.mit.edu/states/05\"\n",
    "  state_html <- read_html(state_url)\n",
    "  occ_node <- html_nodes(state_html, \"table.occupations_table\")\n",
    "  occ_table <- html_table(occ_node)\n",
    "  return(occ_table)\n",
    "}  \n",
    "  \n",
    "    \n",
    "# This wasn't really necessary but showed me how to get the state from the state url just by typing the state number in the arguement.\n",
    "get_state = function(state_num) {\n",
    "  state_url_from_num(state_num)\n",
    "  # \"http://livingwage.mit.edu/states/05\"\n",
    "  return(get_occ_table_from_url(state_url_from_num()))\n",
    "}\n",
    "\n",
    "#step 3\n",
    "#make a function that takes state_num and returns a df\n",
    "#This is all the steps that go into this function (below is the correct function)\n",
    "get_occ_from_state_num = function(state_num){\n",
    "  state_url = paste(\"http://livingwage.mit.edu/states/\",state_num, sep = \"\")\n",
    "  state_html <- read_html(state_url)\n",
    "  occ_node <- html_nodes(state_html, \"table.occupations_table\")\n",
    "  occ_table <- html_table(occ_node)\n",
    "  return(occ_table)\n",
    "}\n",
    "\n",
    "# BEHOLD THE CORRECT FUNCTION!!!! BLESS.\n",
    "get_occ_from_state_num2 = function(state_num){\n",
    "  state_url = state_url_from_num(state_num)\n",
    "  occ_table = get_occ_table_from_url(state_url)\n",
    "  return(occ_table)\n",
    "}\n",
    "  #read url\n",
    "  #get table\n",
    "  #put table in dataframe\n",
    "  #return dataframe\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#step 4\n",
    "# call on individual numbers as a test\n",
    "\n",
    "#step 5\n",
    "# rbind two states together\n",
    "\n",
    "#step 6 function to rbind state to table\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Key Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kurtosis\n",
    "*Defintion: Kurtosis is a measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution. That is, data sets with high kurtosis tend to have heavy tails, or outliers. Data sets with low kurtosis tend to have light tails, or lack of outliers.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Code to Illustrate the concept goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stem & Leaf\n",
    "*Definition: Stem-and-leaf plots are a method for showing the frequency with which certain classes of values occur. You could make a frequency distribution table or a histogram for the values, or you can use a stem-and-leaf plot and let the numbers themselves to show pretty much the same information.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Tendancy\n",
    "*Definition: A measure of central tendency is a single value that attempts to describe a set of data by identifying the central position within that set of data. This is also called summary statistics. Mean, Median, and Mode*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate\n",
    "*Definition: Univariate analysis is the simplest form of analyzing data. “Uni” means “one”, so in other words your data has only one variable. It takes data, summarizes that data and finds patterns in the data.Univariate methods look at one variable (data column) at a time*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate \n",
    "*Includes all statistical techniques for analyzing two or more variables of interest, or if you like, two or more dependent variables. Multivariate methods look at two or more variables at a time to explore\n",
    "relationships*\n",
    "\n",
    "*note: It is almost\n",
    "always a good idea to perform univariate EDA on each of the components of a univariate EDA before performing the multivariate EDA.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Back up: anova, distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
