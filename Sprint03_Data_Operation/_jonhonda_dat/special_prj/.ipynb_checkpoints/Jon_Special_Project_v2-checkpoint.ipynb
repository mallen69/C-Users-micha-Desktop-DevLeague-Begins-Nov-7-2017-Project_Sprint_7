{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "'''\n",
    "OBJECTIVES:\n",
    "1. Build WRS system\n",
    "2. Build Structural BMP Solution evaluator\n",
    "3. Identify minimum BMP solution front for:\n",
    "   individual facilities\n",
    "   facilities w/in departments\n",
    "   facilities w/in city\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clearing old DB\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Define basic SQLAlchemy items:\n",
    "    declarative base object\n",
    "    connection object\n",
    "    session object\n",
    "    DB tables\n",
    "'''\n",
    "#SQLAlchemy library items:\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import Column, Integer, String\n",
    "from sqlalchemy import update, insert\n",
    "from sqlalchemy import ForeignKey\n",
    "from sqlalchemy.orm import relationship #http://docs.sqlalchemy.org/en/latest/orm/basic_relationships.html#relationship-patterns\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "from SQLA_Base import Base #module containing declarative_base\n",
    "from SQLA_conn_man import session, engine #module handling db and connection creation \n",
    "\n",
    "#Table definitions as SQLA classes: \n",
    "from SQLA_DB_base_bmp_feasibility_test_definitions import Base_BMP_Feasibility_Test_Definitions\n",
    "from SQLA_DB_base_bmps import Base_BMPs\n",
    "from SQLA_DB_expressions import Expressions\n",
    "from SQLA_DB_facility_chars import Facility_Chars\n",
    "from SQLA_DB_facility_monthly_rain import Facility_Monthly_Rain\n",
    "from SQLA_DB_facility_risks import Facility_Risks\n",
    "from SQLA_DB_facility_type_has_nel import Facility_Type_Has_NEL\n",
    "from SQLA_DB_facility_types import Facility_Types\n",
    "from SQLA_DB_feasibility_test_questions import Feasibility_Test_Questions\n",
    "from SQLA_DB_pollutant_removal_rates import Pollutant_Removal_Rates\n",
    "from SQLA_DB_wrs_pollutant_risks import WRS_Pollutant_Risks\n",
    "Base.metadata.create_all(engine, checkfirst=True) #create SQLA classes\n",
    "\n",
    "'''\n",
    "Dictionary of \"SQLAlchemy where clause lambda functions\" that importCSV uses to test record uniqueness.\n",
    "used as the where clause in sqlalchemy queries, updates and deletes \n",
    "Form:\n",
    "    TableName:Lambda Function\n",
    "    \n",
    "    TableName is the table name we want to define uniqueness test for\n",
    "    Lambda Function can take on any form but must be made to evaluate the CSV row passed as a dictionary (CSVRowDict in this explanation):\n",
    "        CSVRowDict: {FieldName:CSVColValue, DBTableFieldName:CSVColValue...} \n",
    "            Where: DBTableFieldName is the name of the field associated with the value at CSVColValue on the current row\n",
    "               CSVColValue: a value in the CSV's current row+column corresponding to the DBTableFieldName \n",
    "        *this assumes that field names are unique across table. if not, then method fails (maybe need to extend method?)\n",
    "        \n",
    "e.g.: lambda myRowVal: Base.metadata.tables['people'].c['name'] == CSVRowDict['name']\n",
    "        using lambda function in query will search for CSVRowDict's value for 'name' in the table people, field name \n",
    "if table has no record uniqueness requirement, then enter: TableName:False\n",
    "'''\n",
    "unqTests = {\n",
    "    'facility_chars': lambda CSVRowDict: Base.metadata.tables['facility_chars'].c['Fac_Name'] == CSVRowDict['Fac_Name'],\n",
    "    'facility_monthly_rain': False, #DB schema does not impose uniqueness on records in this table\n",
    "    'facility_type_has_nel': False,\n",
    "    'facility_types': lambda CSVRowDict: Base.metadata.tables['facility_types'].c['Fac_Type'] == CSVRowDict['Fac_Type'],\n",
    "    'wrs_pollutant_risks': False #DB schema does not impose uniqueness on records in this table\n",
    "}\n",
    "\n",
    "import SQLA_main as SQLA_main #import main SQLAlchemy functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define other custom modules\n",
    "\n",
    "'''\n",
    "import expression as Expr\n",
    "import importSpecial as importSpecial #special import functions are defined here\n",
    "import importCSV as importCSV #generic CSV importer ****IMPORTANT NOTE: function assumes csv in the utf-8-sig file format. weird things happen if its not in this format!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading csv for import to Feasibility Questions\n",
      "\n",
      "Reading csv record: Feas-1\n",
      "Adding to variable dictionary: OFFSITE_SD_Exist\n",
      "\n",
      "Reading csv record: Feas-2\n",
      "Adding to variable dictionary: GW_Risk\n",
      "\n",
      "Reading csv record: Feas-3\n",
      "Adding to variable dictionary: GW_Risk\n",
      "\n",
      "Reading csv record: Feas-4\n",
      "Adding to variable dictionary: Soil_Type\n",
      "\n",
      "Reading csv record: Feas-5\n",
      "Adding to variable dictionary: Soil_Type\n",
      "\n",
      "Reading csv record: Feas-6\n",
      "Adding to variable dictionary: Soil_Type\n",
      "\n",
      "Reading csv record: Feas-7\n",
      "Adding to variable dictionary: Count_CB\n",
      "\n",
      "Reading csv record: Feas-8\n",
      "Adding to variable dictionary: Runoff_Type\n",
      "\n",
      "Reading csv record: Feas-9\n",
      "Adding to variable dictionary: TFMR_Exist\n",
      "\n",
      "Reading csv record: Feas-10\n",
      "Adding to variable dictionary: DS_SS_Exist\n",
      "\n",
      "Reading csv record: Feas-11\n",
      "Adding to variable dictionary: Fac_Slope\n",
      "\n",
      "Reading csv record: Feas-12\n",
      "Adding to variable dictionary: Can_Add_SD\n",
      "\n",
      "Reading csv record: Feas-13\n",
      "Adding to variable dictionary: Pave_Area\n",
      "Adding to variable dictionary: BMP_Size(base_bmps~bmp_size_expression_id~bmp_name)\n",
      "\n",
      "Reading csv record: Feas-14\n",
      "Adding to variable dictionary: Unpave_Area\n",
      "Adding to variable dictionary: BMP_Size(base_bmps~bmp_size_expression_id~bmp_name)\n",
      "\n",
      "Reading csv record: Feas-15\n",
      "Adding to variable dictionary: Pave_Area\n",
      "Adding to variable dictionary: Det_Size(base_bmps~bmp_size_expression_id~bmp_name)\n",
      "\n",
      "Reading csv record: Feas-16\n",
      "Adding to variable dictionary: EM_Area\n",
      "\n",
      "Reading csv record: Feas-17\n",
      "Adding to variable dictionary: Dmg_Pave\n",
      "\n",
      "Reading csv record: Feas-18\n",
      "Adding to variable dictionary: Fac_Type\n",
      "\n",
      "Reading csv record: Feas-19\n",
      "Adding to variable dictionary: FP_100_Year\n",
      "\n",
      "Reading csv record: Feas-20\n",
      "Adding to variable dictionary: Runoff_Type\n",
      "\n",
      "Reading csv record: Feas-21\n",
      "Adding to variable dictionary: Ex_Struct_BMP\n",
      "Reading csv for import to base bmp tables\n",
      "\n",
      "Reading csv record: Hydrodynamic Separation\n",
      "Adding to variable dictionary: WQFR\n",
      "Adding to variable dictionary: WQFR\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 1\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  1\n",
      "Added feasibility test def as record:  2\n",
      "Added feasibility test def as record:  3\n",
      "Added feasibility test def as record:  4\n",
      "\n",
      "Reading csv record: Enhanced Media Filtration (Replaceable Cartridge)\n",
      "Adding to variable dictionary: WQFR\n",
      "Adding to variable dictionary: WQFR\n",
      "Adding to variable dictionary: WQFR\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 2\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  5\n",
      "Added feasibility test def as record:  6\n",
      "Added feasibility test def as record:  7\n",
      "Added feasibility test def as record:  8\n",
      "\n",
      "Reading csv record: Biofiltration (Vault)\n",
      "Adding to variable dictionary: WQFR\n",
      "Adding to variable dictionary: WQFR\n",
      "Adding to variable dictionary: WQFR\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 3\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  9\n",
      "Added feasibility test def as record:  10\n",
      "Added feasibility test def as record:  11\n",
      "Added feasibility test def as record:  12\n",
      "\n",
      "Reading csv record: Media Filtration (Pressure)\n",
      "Adding to variable dictionary: WQFR\n",
      "Adding to variable dictionary: WQFR\n",
      "Adding to variable dictionary: WQFR\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 4\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  13\n",
      "Added feasibility test def as record:  14\n",
      "Added feasibility test def as record:  15\n",
      "Added feasibility test def as record:  16\n",
      "\n",
      "Reading csv record: Bioinfiltration / Bioretention\n",
      "Adding to variable dictionary: WQV\n",
      "Adding to variable dictionary: BMP_Size(base_bmps~bmp_size_expression_id~bmp_name)\n",
      "Adding to variable dictionary: WQV\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 5\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  17\n",
      "Added feasibility test def as record:  18\n",
      "Added feasibility test def as record:  19\n",
      "Added feasibility test def as record:  20\n",
      "Added feasibility test def as record:  21\n",
      "Added feasibility test def as record:  22\n",
      "Added feasibility test def as record:  23\n",
      "Added feasibility test def as record:  24\n",
      "\n",
      "Reading csv record: Inlet Insert Unit\n",
      "Adding to variable dictionary: Count_CB\n",
      "Adding to variable dictionary: Count_CB\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 6\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  25\n",
      "\n",
      "Reading csv record: Sand Filtration\n",
      "Adding to variable dictionary: WQV\n",
      "Adding to variable dictionary: WQV\n",
      "Adding to variable dictionary: WQV\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 7\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  26\n",
      "Added feasibility test def as record:  27\n",
      "Added feasibility test def as record:  28\n",
      "Added feasibility test def as record:  29\n",
      "\n",
      "Reading csv record: Coagulation Enhanced Treatment\n",
      "Adding to variable dictionary: WQFR\n",
      "Adding to variable dictionary: WQFR\n",
      "Adding to variable dictionary: WQFR\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 8\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  30\n",
      "Added feasibility test def as record:  31\n",
      "Added feasibility test def as record:  32\n",
      "Added feasibility test def as record:  33\n",
      "\n",
      "Reading csv record: Roofing\n",
      "Adding to variable dictionary: BMP_Size(base_bmps~bmp_size_expression_id~bmp_name)\n",
      "Adding to variable dictionary: EM_Area\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 9\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  34\n",
      "\n",
      "Reading csv record: Paving and Curbing\n",
      "Adding to variable dictionary: BMP_Size(base_bmps~bmp_size_expression_id~bmp_name)\n",
      "Adding to variable dictionary: Dmg_Pave\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 10\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  35\n",
      "\n",
      "Reading csv record: Oil and Water Separators\n",
      "Adding to variable dictionary: WQFR\n",
      "Adding to variable dictionary: WQFR\n",
      "Adding to variable dictionary: WQFR\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 11\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  36\n",
      "Added feasibility test def as record:  37\n",
      "Added feasibility test def as record:  38\n",
      "Added feasibility test def as record:  39\n",
      "Added feasibility test def as record:  40\n",
      "\n",
      "Reading csv record: Vegetative Swales\n",
      "Adding to variable dictionary: WQV\n",
      "Adding to variable dictionary: BMP_Size(base_bmps~bmp_size_expression_id~bmp_name)\n",
      "Adding to variable dictionary: Drainage_Area_Acres\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 12\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  41\n",
      "Added feasibility test def as record:  42\n",
      "Added feasibility test def as record:  43\n",
      "Added feasibility test def as record:  44\n",
      "Added feasibility test def as record:  45\n",
      "Added feasibility test def as record:  46\n",
      "\n",
      "Reading csv record: Detention\n",
      "Adding to variable dictionary: WQV\n",
      "Adding to variable dictionary: WQV\n",
      "Adding to variable dictionary: WQV\n",
      "Reading pollutant removal rate info...\n",
      "Linking feasibility tests w/ base bmp: 13\n",
      "Removed:  0  old feasibility test defs for the base bmp\n",
      "Added feasibility test def as record:  47\n",
      "Added feasibility test def as record:  48\n",
      "Added feasibility test def as record:  49\n",
      "\n",
      "Importing facility characteristics:\n",
      "importing data in CSV rows...\n",
      "imported records in  2  \n",
      "associating records...\n",
      "\n",
      "Importing Facility Rainfall Data:\n",
      "importing data in CSV rows...\n",
      "imported records in  238  \n",
      "associating records...\n",
      "\n",
      "Importing Facility Type Has Effluent Limits:\n",
      "importing data in CSV rows...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Fac_Type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-af8d5abe97c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'\\nImporting Facility Type Has Effluent Limits:'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#import into wrs_pollutant_risks table\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mimportCSV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimportCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Input_Files\\\\nel_exists_facility_types.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munqTests\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Projects\\Big Data School\\BigDataAnalyst_ProjectDocumentation\\Sprint03_Data_Operation\\_jonhonda_dat\\special_prj\\importCSV.py\u001b[0m in \u001b[0;36mimportCSV\u001b[1;34m(csvPath, unqTests)\u001b[0m\n\u001b[0;32m    114\u001b[0m                     \u001b[1;31m#represent as a list of dicts {Table.PKName:PKid} for table of a given record. Each record is 1 element of list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'importing data in CSV rows...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mmyRecsLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_HELPER_importCSVrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheadersDict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCSVrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munqTests\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mCSVrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsvreader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'imported records in '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyRecsLS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'associating records...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Projects\\Big Data School\\BigDataAnalyst_ProjectDocumentation\\Sprint03_Data_Operation\\_jonhonda_dat\\special_prj\\importCSV.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    114\u001b[0m                     \u001b[1;31m#represent as a list of dicts {Table.PKName:PKid} for table of a given record. Each record is 1 element of list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'importing data in CSV rows...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mmyRecsLS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_HELPER_importCSVrow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheadersDict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mCSVrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munqTests\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mCSVrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsvreader\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'imported records in '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyRecsLS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'associating records...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Projects\\Big Data School\\BigDataAnalyst_ProjectDocumentation\\Sprint03_Data_Operation\\_jonhonda_dat\\special_prj\\importCSV.py\u001b[0m in \u001b[0;36m_HELPER_importCSVrow\u001b[1;34m(headersDict, CSVrow, updateWhereLF)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mrec_id\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mSQLA_main\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsertupdateRec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyTable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyRecDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mPKid\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mPKid\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPKCol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#use where clause lambda function to evaluate insert/update\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mrec_id\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mSQLA_main\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsertupdateRec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyTable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmyRecDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mupdateWhereLF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmyTableName\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyRecDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0mmyRowRecDict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mmyTableName\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mPKLS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mrec_id\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#add PK id to record of rows added\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmyRowRecDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-0ef4f3453c75>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(CSVRowDict)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;34m'facility_monthly_rain'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#DB schema does not impose uniqueness on records in this table\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;34m'facility_type_has_nel'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mCSVRowDict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'facility_types'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fac_Type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mCSVRowDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fac_Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[1;34m'facility_types'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mCSVRowDict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'facility_types'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fac_Type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mCSVRowDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Fac_Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[1;34m'wrs_pollutant_risks'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;31m#DB schema does not impose uniqueness on records in this table\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m }\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Fac_Type'"
     ]
    }
   ],
   "source": [
    "#import feasibillity questions, build feasibility expressions\n",
    "importSpecial.importFeasibilityQuestionsCSV('Input_Files\\\\feasibility_test_questions.csv') \n",
    "\n",
    "#import base bmp information including:\n",
    "  #1. imports definitions for cip costs, o&m costs, and BMP sizing to the expressions table\n",
    "  #2. imports pollutant removal rates into pollutant_removal_rates table\n",
    "  #3. creates a record in the base_bmps table using (1) and (2)\n",
    "  #4. feasibility tests\n",
    "importSpecial.importBaseBMPsCSV('Input_Files\\\\bmp_lego_piece.csv') \n",
    "\n",
    "#IMPORT BASIC FACILITY CHARS:\n",
    "print ('\\nImporting facility characteristics:')\n",
    "importCSV.importCSV('Input_Files\\\\facility_chars.csv', unqTests)\n",
    "\n",
    "#IMPORT FACILITY RAINFALL EXTRACTED FROM http://rainfall.geography.hawaii.edu/downloads.html\n",
    "print ('\\nImporting Facility Rainfall Data:')\n",
    "importCSV.importCSV('Input_Files\\\\FacilityRainfallData.csv', unqTests)\n",
    "\n",
    "#IMPORT EFFLUENT LIMITS FOR FACILITY TYPES: (either by Priority Based Plan, Table 3 or as City operational assignment)\n",
    "\n",
    "\n",
    "print ('\\nImporting Facility Type Has Effluent Limits:') #import into wrs_pollutant_risks table\n",
    "importCSV.importCSV('Input_Files\\\\nel_exists_facility_types.csv', unqTests)\n",
    "\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.close()\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
