{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "'''\n",
    "OBJECTIVES:\n",
    "1. Build WRS system\n",
    "2. Build Structural BMP Solution evaluator\n",
    "3. Identify minimum BMP solution front for:\n",
    "   individual facilities\n",
    "   facilities w/in departments\n",
    "   facilities w/in city\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<People(name='Jon', ssn='579-98-0136', age='56')> <Locations(city='aiea', country='USA', people_id='1')>\n",
      "<People(name='becky', ssn='221-69-4975', age='2')> <Locations(city='kremling', country='USA', people_id='2')>\n",
      "<People(name='Jino', ssn='789-87-1025', age='88')> <Locations(city='waikiki', country='Japan', people_id='3')>\n",
      "<People(name='Jon', ssn='579-98-0136', age='56')> <Locations(city='denver', country='USA', people_id='1')>\n",
      "<People(name='Jon', ssn='579-98-0136', age='56')> <Locations(city='tacoma', country='USA', people_id='1')>\n",
      "<People(name='becky', ssn='221-69-4975', age='2')> <Locations(city='denver', country='USA', people_id='2')>\n",
      "<People(name='Jon', ssn='579-98-0136', age='56')> <Locations(city='los angeles', country='USA', people_id='1')>\n",
      "<People(name='Kris', ssn='698-42-9678', age='31')> <Locations(city='pullman', country='USA', people_id='4')>\n",
      "<People(name='Kris', ssn='698-42-9678', age='31')> <Locations(city='honolulu', country='USA', people_id='4')>\n"
     ]
    }
   ],
   "source": [
    "#Define basic SQLAlchemy items:\n",
    "#import a single csv containing 2 or more tables. Tables can have PK-FK relations.\n",
    "#build SQLAlchemy objects, build DB:\n",
    "#connect to SQLite DB w/ SQLAlchemy ORM:\n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "#deprecate working w/ dbs located on disk for now.\n",
    "# dbfilename = '_jonhonda_files//test.db' #right now code writes to memory, later change to write to disk not used right now.\n",
    "# print (\"\\nClearing old DB\")\n",
    "# try:\n",
    "#     os.remove(dbfilename)\n",
    "# except FileNotFoundError as err:\n",
    "#     print (\"no need to remove db file\")####it's okay if file doesn't exist. ####\n",
    "# engine = create_engine('sqlite:///'+ dbfilename, echo = False)\n",
    "\n",
    "from SQLA_Base import Base\n",
    "\n",
    "#for now work w/ dbs in memory\n",
    "engine = create_engine('sqlite:///:memory:', echo = False)\n",
    "\n",
    "#NOW DEFINE DB SCHEMA (THIS DOESN'T WRITE SCHEMA TO DB, JUST TO SQLALCHEMY CLASSES AND OBJECTS)\n",
    "#define an SQLAlchemy base class to maintain catalog of classes and tables relative to this base\n",
    "from SQLA_DB_User import People\n",
    "from SQLA_DB_Locations import Locations\n",
    "Base.metadata.create_all(engine, checkfirst=True) #create tables\n",
    "\n",
    "#now generate session object:\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "Session = sessionmaker(bind=engine) #define Session class, which is a factory for making session objects (poor naming choice, in my opinion - why the do it this way??!)\n",
    "session = Session() #make a session\n",
    "\n",
    "\n",
    "#use the base class to define mapped classes in terms of it:\n",
    "from sqlalchemy import Column, Integer, String\n",
    "from sqlalchemy import update, insert\n",
    "from sqlalchemy import ForeignKey\n",
    "from sqlalchemy.orm import relationship #http://docs.sqlalchemy.org/en/latest/orm/basic_relationships.html#relationship-patterns\n",
    "from sqlalchemy import inspect\n",
    "\n",
    "#NOW WRITE SCHEMA TO DB (THIS WRITES TO SQLITE DB):\n",
    "# Base.metadata.create_all(engine) #build DB schema from Base objects\n",
    "\n",
    "def getPKFieldNames (myTable):\n",
    "    \"\"\"Gets primary key field for the given table.\n",
    "\n",
    "    Uses SQLAlchemy's .primary_key table attribute.\n",
    "    Since SQLAlchemy's .primary_key table attribut returns a list, we will use just the 1'st value\n",
    "\n",
    "    Args:\n",
    "        myTable: the metadata.table that we want to insert/update on.\n",
    "\n",
    "    Returns\n",
    "        the primary key field as an integer\n",
    "\n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"\n",
    "     #get Table.primary key using inspector. inspector requires iterator, so iterate pk into a list\n",
    "    return [PKname.key for PKname in inspect(myTable).primary_key][0]#Use 1st element of list.\n",
    "\n",
    "def insertupdateRec(myTable, setFieldVals, whereConstraint):\n",
    "    \"\"\"Inserts or updates values into a table's fields subject to some constraints.\n",
    "\n",
    "    Only works on one record row at a time. So only pass in 1 record's args\n",
    "\n",
    "    Args:\n",
    "        myTable: the metadata.table that we want to insert/update on.\n",
    "        setFieldVals: a single record represented as a dictionary of fields\n",
    "                    and values to be inserted/updated {fieldname:val, fieldname:val}\n",
    "        whereConstraint: where clause used to determine if record already exists/update on\n",
    "                    passed in as a lambda function\n",
    "\n",
    "    Returns\n",
    "        the primary key id value of the table we updated/inserted to.\n",
    "        primary key is returned as an integer.\n",
    "\n",
    "    Raises:\n",
    "        None.\n",
    "    \"\"\"\n",
    "    PKName = getPKFieldNames(myTable) #shove parts of this into getPKFieldNames\n",
    "    ret = session.query(myTable.c[PKName]).filter(whereConstraint) #determine existance of record w/ whereConstraint\n",
    "    try:\n",
    "        PKid = ret.one()[0] #get value of matching record. errors if no record exists\n",
    "        updateRec(myTable, setFieldVals, whereConstraint)\n",
    "    except:\n",
    "        PKid = insertRec(myTable, setFieldVals)\n",
    "    return PKid\n",
    "\n",
    "def insertRec(myTable, setFieldVals):\n",
    " #insert a single record:\n",
    "        #ex: insertRec(FkTable, {FkFKField.name:arecPKid})\n",
    "        #updateTable: table to update\n",
    "        #setFieldVals: dictionary of fields and vals to be updated: {fieldname:val,fieldname:val}\n",
    "    rec = session.execute(myTable.insert(),setFieldVals)\n",
    "    return rec.inserted_primary_key[0]\n",
    "\n",
    "def updateRec(updateTable, setFieldVals, updateWhereLF):\n",
    "    #update a single records:\n",
    "        #ex: updateRecs(FkTable, {FkFKField.name:arecPKid}, (lambda x,y: x == y)(FkPKField, constrVal))\n",
    "        #updateTable: table to update\n",
    "        #setFieldVals: dictionarinserted_proimary_key[0]y of fields and vals to be updated: {fieldname:val,fieldname:val}\n",
    "        #updateWhereLF: update constraints where constraint, passed as a lambda function, is true\n",
    "    u = update(updateTable) #make a SQLAlchemy update object for updateTable\n",
    "    u = u.values(setFieldVals) #set update values\n",
    "    u = u.where(updateWhereLF) #define update's where clause\n",
    "    rec = session.execute(u) #execute the update\n",
    "\n",
    "def _HELPER_importCSVrow(headersDict, CSVrow, updateWhereLF = False):\n",
    "    #importCSV helper function to handle inserting a single CSV row\n",
    "    #currently forces insert (will be changed to discriminate based on existance of record using lambda function)\n",
    "        #headersDict: dictionary of form: {table.field:[table,field]}\n",
    "        #CSVrow: single row of a csv reader loop\n",
    "        #updateWhereLF:where Clause as a lambda function to pass to insert/updater to determinE record existance\n",
    "                        #False to force insert\n",
    "    #return primary keys inserted/updated using CSVrow values\n",
    "    C_TABLE = 0 #header 0th element is table name\n",
    "    C_FIELD = 1 #header 1st element is field name\n",
    "    myTempRecDicts = {aheader[C_TABLE]:{} for aheader in headersDict.values()} #initialize dictionary of tables #and their associated list of  records. note the empty dict. needed b/c we will update that empty dict\n",
    "    for aheader, avalue in zip(headersDict.values(),CSVrow): #write current header-value pair to a temp dictionary\n",
    "        mytmpDict = {aheader[C_FIELD]:avalue}\n",
    "        myTempRecDicts[aheader[C_TABLE]].update(mytmpDict) #place temp dictionary value into current rec's dictionary of tables an assoc. header-values\n",
    "    myRowRecDict={} #dictionary of record ids inserted/updated for current row: {PKName:PK_ID}\n",
    "    for myTableName,myRecDict in myTempRecDicts.items():\n",
    "        #insert table and record's return primary key\n",
    "        myTable = Base.metadata.tables[myTableName]\n",
    "        PKLS = getPKFieldNames(myTable)#get primary key field for myTable\n",
    "        if updateWhereLF==False or updateWhereLF[myTableName] == False:#force insert (update if PKid==-1234 which can't happen)\n",
    "            PKCol = myTable.c[PKLS] #get sqlAlchemy object for PK Field\n",
    "            rec_id = insertupdateRec(myTable, myRecDict, (lambda PKid: PKid == -1234)(PKCol))\n",
    "        else: #use where clause lambda function to evaluate insert/update\n",
    "            rec_id = insertupdateRec(myTable, myRecDict, updateWhereLF[myTableName](myRecDict))\n",
    "        myRowRecDict.update({myTableName + '.' + PKLS:rec_id}) #add PK id to record of rows added\n",
    "    return myRowRecDict\n",
    "\n",
    "def _HELPER_assocKEYS(myRecsLS, tablesLS):\n",
    "    #helper function to associate primary-foreign key pairings during importCSV of mixed tables:\n",
    "     #find PK-FK links between tables\n",
    "    PkFkLS = [] #init empty pk-fk list, of assumed form: [[PKTable.PKCOL,FKTable.FKCol],[PKTable.PKCOL,FKTable.FKCol],...]\n",
    "    for myTable in tablesLS:\n",
    "        for col in Base.metadata.tables[myTable].c:\n",
    "            if col.foreign_keys:PkFkLS.append([str(list(col.foreign_keys)[0].column),str(col)])\n",
    "    C_PK=0\n",
    "    C_FK=1\n",
    "    C_TABLE = 0 #header 0th element is table name\n",
    "    C_FIELD = 1 #header 1st element is field name\n",
    "    #update the foreign key id for each PK-FK relationship affected by csv row data import:\n",
    "    for aRec in myRecsLS:\n",
    "        for aPkFk in PkFkLS:\n",
    "            arecPKid=-1234\n",
    "            if aPkFk[C_PK] in aRec: #if current PkFk pair is part of aRec then\n",
    "            #update FK_TABLE SET FK_ID = xxx WHERE FK_TABLE'S PK = XXX\n",
    "            #get data we need:\n",
    "                FkLS = aPkFk[C_FK].split('.') #make [tablename, fieldname] of the Table-Field holding the Fk we want to update\n",
    "                FkTable = Base.metadata.tables[FkLS[C_TABLE]] #assign foreign key table\n",
    "                FkFKField = FkTable.c[FkLS[C_FIELD]] #assign FK table's FK field\n",
    "                FkPKFieldName = [PKname.key for PKname in inspect(FkTable).primary_key][0] #get FK Table.primary key using inspector. inspector requires iterator, so iterate pk into a list\n",
    "                FkPKField = FkTable.c[FkPKFieldName] #assign FK table's PK field\n",
    "                arecPKid = aRec[aPkFk[C_PK]] #get PKid for aRec[aPkFk] corresponding to current aPkFk's PK name\n",
    "                #now build updater:\n",
    "                constrVal = aRec[FkTable.name + '.' + FkPKField.name]\n",
    "                updateRec(FkTable, {FkFKField.name:arecPKid}, (lambda x,y: x == y)(FkPKField, constrVal))\n",
    "\n",
    "def importCSV(csvPath, unqTests):\n",
    "    #assume header given in form: tablename.fieldname\n",
    "    # assume all table and header names match database table and field names\n",
    "    import csv\n",
    "    C_TABLE = 0 #header 0th element is table name\n",
    "    C_FIELD = 1 #header 1st element is field name\n",
    "    with open(csvPath, 'rt', encoding='utf-8-sig') as csvfile:\n",
    "        csvreader = csv.reader(csvfile,dialect='excel')\n",
    "        rawheadersLS = next(csvreader) #read raw csv headers to list\n",
    "        headersDict = {myheader:myheader.split('.') for myheader in rawheadersLS} #collect rawheader (Table.FieldName) and its table & field compenent\n",
    "        #make list of tables:\n",
    "        tablesLS=[]\n",
    "        for aheader in headersDict.values():\n",
    "            if aheader[C_TABLE] not in tablesLS:\n",
    "                tablesLS.append(aheader[C_TABLE])\n",
    "        #record primary keys inserted/updated during importing of csv row data.\n",
    "                    #represent as a list of dicts {Table.PKName:PKid} for table of a given record. Each record is 1 element of list\n",
    "        myRecsLS = [_HELPER_importCSVrow(headersDict,CSVrow, unqTests) for CSVrow in csvreader]\n",
    "    _HELPER_assocKEYS(myRecsLS, tablesLS)\n",
    "    session.commit()\n",
    "\n",
    "'''\n",
    "Dictionary of \"SQLAlchemy where clause lambda functions\" that tests record uniqueness.\n",
    "e.g. entries in the 'name' field of the people table must be unique.\n",
    "Therefore, we determine whether to insert/update a csv row into the people table based on\n",
    "whether the csv row's name field value exists in the people table.\n",
    "\n",
    "if table has no record uniqueness requirement, then enter: TableName:False\n",
    "'''\n",
    "unqTests = {\n",
    "    'people': lambda RowVal: Base.metadata.tables['people'].c['name'] == RowVal['name'],\n",
    "    'locations': False\n",
    "}\n",
    "\n",
    "importCSV('testlab\\\\2_table_input.csv', unqTests)\n",
    "#test some reords\n",
    "for u, a in session.query(People, Locations).filter(People.id==Locations.people_id):\n",
    "    print (u,a)\n",
    "\n",
    "session.close()\n",
    "engine.dispose()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
